{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pylab\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "from tensorflow.contrib.layers.python.layers import utils\n",
    "\n",
    "import resnet_v2 as resnet\n",
    "# import cv2\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HourGlass(inputs,scope):\n",
    "    levels_down = {}\n",
    "    levels_up = {}\n",
    "    LEVELS = 5\n",
    "    net = inputs\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        with tf.variable_scope(\"DownSample\"):\n",
    "            for i in range(LEVELS):\n",
    "                if i == 0:\n",
    "                    net = tf.layers.conv2d(net,64,(3,3),(2,2),'same',name=\"Conv{}\".format(2*i),activation=tf.nn.relu)\n",
    "                    levels_down[2*i] = net\n",
    "                    net = tf.layers.conv2d(net,64,(3,3),(2,2),'same',name=\"Conv{}\".format(2*i+1),activation=tf.nn.relu)\n",
    "                    levels_down[2*i+1] = net\n",
    "                else:\n",
    "                    net = tf.layers.conv2d(net,32,(3,3),(1,1),'same',name=\"Conv{}\".format(2*i),activation=tf.nn.relu)\n",
    "                    levels_down[2*i] = net\n",
    "                    net = tf.layers.conv2d(net,32,(3,3),(2,2),'same',name=\"Conv{}\".format(2*i+1),activation=tf.nn.relu)\n",
    "                    levels_down[2*i+1] = net\n",
    "        with tf.variable_scope(\"Bottleneck\"):\n",
    "            net = tf.layers.conv2d(net,16,(1,1),(1,1),name=\"bottleneck\")\n",
    "\n",
    "        with tf.variable_scope(\"UpSample\"):\n",
    "            for i in reversed(range(LEVELS)):\n",
    "                if i != 0:\n",
    "                    net = tf.layers.conv2d_transpose(net,32,(3,3),(2,2),'same',name=\"TransposeConv{}\".format(2*i+1),\n",
    "                                                     activation=tf.nn.relu)\n",
    "                    levels_up[2*i+1] = net\n",
    "                    net = tf.layers.conv2d_transpose(net,32,(3,3),(1,1),'same',name=\"TransposeConv{}\".format(2*i),\n",
    "                                                     activation=tf.nn.relu)\n",
    "                    levels_up[2*i] = net\n",
    "                    net = tf.concat([net, levels_down[2*i]],axis=3)\n",
    "                else:\n",
    "                    net = tf.layers.conv2d_transpose(net,16,(3,3),(2,2),'same',name=\"TransposeConv{}\".format(2*i+1),\n",
    "                                                     activation=tf.nn.relu)\n",
    "                    levels_up[2*i+1] = net\n",
    "#                     net = tf.layers.conv2d_transpose(net,16,(3,3),(2,2),'same',name=\"TransposeConv{}\".format(2*i),\n",
    "#                                                      activation=tf.nn.relu)\n",
    "#                     levels_up[2*i] = net\n",
    "                    \n",
    "    return net, levels_down, levels_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keypoint_CrossEntropyLoss(prediction_maps, keypoint_masks, labels, L=5.0, scope=\"keypointLoss\"):\n",
    "    \"\"\"\n",
    "    heat_maps = predictions from network\n",
    "    keypoints (N,17,2) = actual keypoint locations\n",
    "    labels (N,17,1) = 0 if invalid, 1 if occluded, 2 if valid\n",
    "    \"\"\"\n",
    "    losses = tf.nn.sigmoid_cross_entropy_with_logits(logits=prediction_maps,labels=keypoint_masks)\n",
    "    labels = tf.reshape(labels,[-1,1,1,17])\n",
    "    losses = tf.multiply(losses,labels) # set loss to zero for invalid keypoints (labels=0)\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keypoint_SquaredErrorLoss(prediction_maps, keypoint_masks, labels, L=5.0, scope=\"keypointLoss\"):\n",
    "    \"\"\"\n",
    "    heat_maps = predictions from network\n",
    "    keypoints (N,17,2) = actual keypoint locations\n",
    "    labels (N,17,1) = 0 if invalid, 1 if occluded, 2 if valid\n",
    "    \"\"\"\n",
    "    losses = tf.squared_difference(prediction_maps,keypoint_masks)\n",
    "    labels = tf.reshape(labels,[-1,1,1,17])\n",
    "    losses = tf.multiply(losses,labels) # set loss to zero for invalid keypoints (labels=0)\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(base_dir,image_dir,ann_file):\n",
    "    image_path = '{}/images/{}'.format(baseDir,image_dir)\n",
    "    ann_path='{}/annotations/{}.json'.format(baseDir,ann_file)\n",
    "\n",
    "    return image_path, ann_path\n",
    "    \n",
    "# define the path to the annotation file corresponding to the images you want to work with\n",
    "baseDir='/Users/kyle/Repositories/coco'\n",
    "\n",
    "trainData='person_keypoints_train2014'\n",
    "valData='person_keypoints_val2014'\n",
    "testData='image_info_test-dev2015'\n",
    "\n",
    "imageTrainDir = 'train2014'\n",
    "imageValDir = 'val2014'\n",
    "imageTestDir = 'test2015'\n",
    "\n",
    "train_img_path, train_ann_path = get_data(baseDir,imageTrainDir,trainData)\n",
    "val_img_path, val_ann_path = get_data(baseDir,imageValDir,valData)\n",
    "\n",
    "# initialize a coco object\n",
    "coco = COCO(train_ann_path)\n",
    "\n",
    "# get all images containing the 'person' category\n",
    "catIds = coco.getCatIds(catNms=['person'])\n",
    "imgIds = coco.getImgIds(catIds=catIds)\n",
    "\n",
    "# Just for dealing with the images on my computer (not necessary when working with the whole dataset)\n",
    "catIds = imgIds[0:30]\n",
    "imgIds = imgIds[0:30]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    VGG_MEAN = tf.reshape(tf.constant([123.68, 116.78, 103.94]),[1,1,3])\n",
    "    NUM_KEYPOINTS = 17\n",
    "    BATCH_SIZE = 10\n",
    "    L = 10.0 # keypoint effective radius\n",
    "    \n",
    "    def extract_annotations(filename, imgID, coco=coco):\n",
    "        anns = coco.loadAnns(coco.getAnnIds(imgID,catIds=[1],iscrowd=None))\n",
    "        ann = max([ann for ann in anns], key=lambda item:item['area']) # extract annotation for biggest instance\n",
    "        bbox = np.array(np.floor(ann['bbox']),dtype=int)\n",
    "        keypoints = np.reshape(ann['keypoints'],(-1,3))\n",
    "        mask = coco.annToMask(ann)\n",
    "        \n",
    "        return filename, bbox, keypoints, mask\n",
    "    \n",
    "    def preprocess_image_tf(filename, bbox_tensor, keypoints_tensor, mask, D = tf.constant(256.0)):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        resized_image (N,D,D,3) - cropped, padded (if needed), scaled to square image of size D\n",
    "        resized_mask (N,D,D,1) - cropped, padded (if needed), scaled to square mask of size D\n",
    "        pts (N,2,17) - keypoint coordinates (i,j) scaled to match up with resized_image\n",
    "        labels (N,1,17) - values corresponding to pts: {0: invalid, 1:occluded, 2:valid}\n",
    "        \"\"\"\n",
    "        image_string = tf.read_file(filename)\n",
    "        image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "        image = tf.cast(image_decoded, tf.float32)\n",
    "\n",
    "        mask = tf.transpose([mask],[1,2,0])\n",
    "        bbox_tensor = tf.to_float(bbox_tensor)\n",
    "        keypoints_tensor = tf.to_float(keypoints_tensor)\n",
    "\n",
    "        sideLength = tf.reduce_max(bbox_tensor[2:],axis=0)\n",
    "        centerX = tf.floor(bbox_tensor[0] + tf.divide(bbox_tensor[2],tf.constant(2.0)))\n",
    "        centerY = tf.floor(bbox_tensor[1] + tf.divide(bbox_tensor[3],tf.constant(2.0)))\n",
    "        center = tf.stack([centerX,centerY])\n",
    "\n",
    "        corner1 = tf.to_int32(tf.minimum(tf.maximum(tf.subtract(center, tf.divide(sideLength,tf.constant(2.0))),0),\n",
    "                             tf.reverse(tf.to_float(tf.shape(image)[:2]),tf.constant([0]))))\n",
    "        corner2 = tf.to_int32(tf.minimum(tf.maximum(tf.add(center, tf.divide(sideLength,tf.constant(2.0))),0),\n",
    "                             tf.reverse(tf.to_float(tf.shape(image)[:2]),tf.constant([0]))))\n",
    "        i_shape = tf.subtract(corner2,corner1)\n",
    "        d_shape = tf.subtract(tf.to_int32(sideLength),i_shape)\n",
    "\n",
    "        scale = tf.divide(D, sideLength)\n",
    "        cropped_image = tf.image.crop_to_bounding_box(image,corner1[1],corner1[0],\n",
    "                                                      tf.subtract(corner2,corner1)[1],tf.subtract(corner2,corner1)[0])\n",
    "        cropped_mask = tf.image.crop_to_bounding_box(mask,corner1[1],corner1[0],\n",
    "                                                      tf.subtract(corner2,corner1)[1],tf.subtract(corner2,corner1)[0])\n",
    "\n",
    "        dX = tf.floor(tf.divide(d_shape,tf.constant(2)))\n",
    "        dY = tf.ceil(tf.divide(d_shape,tf.constant(2)))\n",
    "\n",
    "        pts, labels = tf.split(keypoints_tensor,[2,1],axis=1)\n",
    "        pts = tf.subtract(pts,tf.to_float(corner1)) # shift keypoints\n",
    "        pts = tf.add(pts,tf.to_float(dX)) # shift keypoints\n",
    "        pts = tf.multiply(pts,scale) # scale keypoints\n",
    "\n",
    "        # set invalid pts to 0\n",
    "        inbounds = tf.less(pts,D)\n",
    "        inbounds = tf.multiply(tf.to_int32(inbounds), tf.to_int32(tf.greater(pts,0)))\n",
    "        pts = tf.multiply(pts,tf.to_float(inbounds))\n",
    "        pts = tf.transpose(pts,[1,0])\n",
    "        labels = tf.transpose(labels,[1,0])\n",
    "\n",
    "        padded_image = tf.image.pad_to_bounding_box(cropped_image,tf.to_int32(dX[1]),tf.to_int32(dX[0]),\n",
    "                                                    tf.to_int32(sideLength),tf.to_int32(sideLength))\n",
    "        padded_mask = tf.image.pad_to_bounding_box(cropped_mask,tf.to_int32(dX[1]),tf.to_int32(dX[0]),\n",
    "                                                    tf.to_int32(sideLength),tf.to_int32(sideLength))\n",
    "\n",
    "        resized_image = tf.image.resize_images(padded_image,tf.constant([256,256]),tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        resized_image = resized_image - VGG_MEAN\n",
    "        resized_mask = tf.image.resize_images(padded_mask,tf.constant([256,256]),tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        return resized_image, resized_mask, pts, labels\n",
    "\n",
    "    def scaleDownMaskAndKeypoints(image, mask, pts, labels):\n",
    "        mask = tf.image.resize_images(mask,tf.constant([128,128]),tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        pts = tf.multiply(pts,tf.constant(0.5))\n",
    "        return image, mask, pts, labels\n",
    "    \n",
    "    def generate_keypoint_masks(image, mask, keypoints, labels, D=128.0, L=L):\n",
    "        X, Y = tf.meshgrid(tf.linspace(0.0,128.0,128),tf.linspace(0.0,128.0,128))\n",
    "        X = tf.reshape(X,[128,128,1])\n",
    "        Y = tf.reshape(Y,[128,128,1])\n",
    "        X_stack = tf.tile(X,tf.constant([1,1,17],dtype=tf.int32))\n",
    "        Y_stack = tf.tile(Y,tf.constant([1,1,17],dtype=tf.int32))\n",
    "\n",
    "        pts = tf.reshape(keypoints,[1,2,17])\n",
    "        ptsX, ptsY = tf.split(pts,[1,1],axis=1)\n",
    "        d1 = tf.square(tf.subtract(X_stack,ptsX))\n",
    "        d2 = tf.square(tf.subtract(Y_stack,ptsY))\n",
    "\n",
    "        pt_masks = tf.multiply(tf.divide(tf.constant(1.0),tf.add(d1,d2)+L),L)\n",
    "        return image, mask, pt_masks, pts, labels\n",
    "    \n",
    "    ########## DATASET ###########\n",
    "    \n",
    "    with tf.variable_scope(\"DataSet\"):\n",
    "        # Initialize train_dataset\n",
    "        filenames = tf.constant(['{}/COCO_train2014_{:0>12}.jpg'.format(train_img_path,imgID) for imgID in imgIds])\n",
    "        imgID_tensor = tf.constant(imgIds)\n",
    "\n",
    "        train_dataset = tf.contrib.data.Dataset.from_tensor_slices((filenames,imgID_tensor))\n",
    "        # Extract Annotations via coco interface\n",
    "        train_dataset = train_dataset.map(lambda filename, imgID: tf.py_func(extract_annotations, [filename, imgID], \n",
    "                                                                     [filename.dtype, tf.int64, tf.int64, tf.uint8]))\n",
    "        # All other preprocessing in tensorflow\n",
    "        train_dataset = train_dataset.map(preprocess_image_tf)\n",
    "        train_dataset = train_dataset.map(scaleDownMaskAndKeypoints)\n",
    "        train_dataset = train_dataset.map(generate_keypoint_masks)\n",
    "\n",
    "        # BATCH\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "        train_dataset = train_dataset.batch(10) # must resize images to make them match\n",
    "        iterator = tf.contrib.data.Iterator.from_structure(train_dataset.output_types,train_dataset.output_shapes)\n",
    "        # resized_image, resized_mask, pts, labels = iterator.get_next()\n",
    "#         images, masks, pts, labels = iterator.get_next()\n",
    "        images, masks, kpt_masks, pts, labels = iterator.get_next()\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "    \n",
    "    with tf.variable_scope(\"KyleNet\") as sc:\n",
    "        backbone, levels_down, levels_up = HourGlass(images,sc)\n",
    "        \n",
    "        with tf.variable_scope(\"MaskLoss\"):\n",
    "            maskPrediction = tf.layers.conv2d(backbone,1,(3,3),(1,1),'same',name='MaskPred')\n",
    "            maskError = tf.nn.sigmoid_cross_entropy_with_logits(logits=maskPrediction,labels=tf.to_float(masks))\n",
    "            maskLoss = tf.reduce_sum(maskError)\n",
    "        \n",
    "        with tf.variable_scope(\"KeypointLoss\") as sc2:\n",
    "            keypointPredictions = tf.layers.conv2d(backbone,NUM_KEYPOINTS,(3,3),(1,1),'same',name='KeypointPreds')\n",
    "            keypointLoss = keypoint_CrossEntropyLoss(keypointPredictions,kpt_masks,labels,scope=sc2)\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        file_writer = tf.summary.FileWriter('/tmp/HourGlassNet/1')\n",
    "        file_writer.add_graph(sess.graph)\n",
    "        \n",
    "        # initialize variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # initialize dataset\n",
    "        sess.run(train_init_op) \n",
    "        masks, kpt_masks, mask_pred, kpt_pred, mask_loss, kpt_loss = sess.run([masks, kpt_masks, maskPrediction, \n",
    "                                                             keypointPredictions, maskLoss, keypointLoss])\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 3\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(mask_pred[i][:,:,0])\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(kpt_pred[i][:,:,0])\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(masks[i][:,:,0])\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(np.sum(kpt_masks[i],axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init_fn(sess)  # load the pretrained weights\n",
    "# sess.run(fc8_init)  # initialize the new fc8 layer\n",
    "sess.run(train_init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# resized_image, resized_mask, pts, labels = sess.run(next_element)\n",
    "\n",
    "try:\n",
    "    I, M, P, L = sess.run([images, masks, pts, labels], {is_training: True})\n",
    "    plt.imshow(I[0])\n",
    "    plt.imshow(M[0][:,:,0],alpha=0.5)\n",
    "    plt.scatter(P[0][(np.reshape(L[0],-1)==2),0],P[0][(np.reshape(L[0],-1)==2),1],c=\"r\")\n",
    "except tf.errors.OutOfRangeError:\n",
    "    sess.run(train_init_op)\n",
    "    print(\"Reinitialized Dataset Iterator...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Playing around with ResNet V2 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "D = 225\n",
    "images = tf.placeholder(tf.float32, (BATCH_SIZE,D,D,3))\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "resnet_v2 = tf.contrib.slim.nets.resnet_v2\n",
    "with slim.arg_scope(resnet_v2.resnet_arg_scope()):\n",
    "    logits, endpoints = resnet_v2.resnet_v2_50(\n",
    "        inputs=images,\n",
    "        num_classes=10,\n",
    "        is_training=is_training,\n",
    "        reuse=None,\n",
    "        output_stride=16,\n",
    "        scope='resnet_v2_50'\n",
    "        )\n",
    "\n",
    "# model_path = 'checkpoints/resnet_v2_50.ckpt'\n",
    "# assert(os.path.isfile(model_path))\n",
    "# # Backbone Variables - remember to exclude all variables above backbone (including block4 and logits)\n",
    "# variables_to_restore = tf.contrib.framework.get_variables_to_restore(exclude=['resnet_v2_50/block4','resnet_v2_50/postnorm','resnet_v2_50/logits'])\n",
    "# # Head variables\n",
    "# # Note: We would need another set of variables and another initializer to capture the logits as well\n",
    "# other_variables = tf.contrib.framework.get_variables('resnet_v2_50/block4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_8:0' shape=(1, 72, 72, 3) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters = tf.placeholder(tf.float32,[1,7,7,3,64])\n",
    "padded_filters = tf.pad(filters,tf.constant([[0,0],[1,1],[1,1],[0,0],[0,0]]),'CONSTANT')\n",
    "filter_list = tf.unstack(padded_filters,axis=4)\n",
    "H = int(round(np.sqrt(len(filter_list))))\n",
    "W = int(len(filter_list)/H)\n",
    "weight_strips = [tf.concat(filter_list[8*i:8*(i+1)],axis=1) for i in range(W)]\n",
    "weight_image = tf.concat(weight_strips,axis=2)\n",
    "weight_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_66:0' shape=(10, 464, 464, 1) dtype=float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations1 = endpoints['resnet_v2_50/block1/unit_1/bottleneck_v2/conv2']\n",
    "padded_activations = tf.pad(activations1,tf.constant([[0,0],[1,0],[1,0],[0,0]]),'CONSTANT')\n",
    "expanded_activations = tf.expand_dims(padded_activations,axis=3)\n",
    "activations_list = tf.unstack(expanded_activations,axis=4)\n",
    "H = int(round(np.sqrt(len(activations_list))))\n",
    "W = int(len(activations_list)/H)\n",
    "activation_strips = [tf.concat(activations_list[8*i:8*(i+1)],axis=1) for i in range(W)]\n",
    "activation_image = tf.concat(activation_strips,axis=2)\n",
    "activation_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFilterImageSummary(filters,name=None):\n",
    "    padded_filters = tf.pad(filters,tf.constant([[0,0],[1,1],[1,1],[0,0],[0,0]]),'CONSTANT')\n",
    "    filter_list = tf.unstack(padded_filters,axis=4)    \n",
    "    H,W = highestPrimeFactorization(len(filter_list))\n",
    "    weight_strips = [tf.concat(filter_list[8*i:8*(i+1)],axis=1) for i in range(W)]\n",
    "    weight_image = tf.concat(weight_strips,axis=2)\n",
    "    return weight_image\n",
    "    \n",
    "def getActivationImageSummary(activations,name=None):\n",
    "    padded_activations = tf.pad(activations,tf.constant([[0,0],[1,0],[1,0],[0,0]]),'CONSTANT')\n",
    "    expanded_activations = tf.expand_dims(padded_activations,axis=3)\n",
    "    activations_list = tf.unstack(expanded_activations,axis=4)\n",
    "    H,W = highestPrimeFactorization(len(activations_list))\n",
    "    activation_strips = [tf.concat(activations_list[H*i:H*(i+1)],axis=1) for i in range(W)]\n",
    "    activation_image = tf.concat(activation_strips,axis=2)\n",
    "    return activation_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_273:0' shape=(1, 72, 72, 3) dtype=float32>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getFilterImageSummary(tf.placeholder(tf.float32,[1,7,7,3,64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_290:0' shape=(10, 480, 480, 1) dtype=float32>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block1_activations = endpoints['resnet_v2_50/block1']\n",
    "block2_activations = endpoints['resnet_v2_50/block2']\n",
    "block3_activations = endpoints['resnet_v2_50/block3']\n",
    "block4_activations = endpoints['resnet_v2_50/block4']\n",
    "getActivationImageSummary(block1_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_323:0' shape=(10, 256, 512, 1) dtype=float32>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getActivationImageSummary(block2_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_356:0' shape=(10, 512, 512, 1) dtype=float32>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getActivationImageSummary(block3_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_421:0' shape=(10, 512, 1024, 1) dtype=float32>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getActivationImageSummary(block4_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'resnet_v2_50/block1/unit_1/bottleneck_v2/add:0' shape=(10, 57, 57, 256) dtype=float32>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block1_unit1_activations = endpoints['resnet_v2_50/block1/unit_1/bottleneck_v2']\n",
    "block1_unit1_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet_v2_50/conv1\n",
      "resnet_v2_50/block1/unit_1/bottleneck_v2/shortcut\n",
      "resnet_v2_50/block1/unit_1/bottleneck_v2/conv1\n",
      "resnet_v2_50/block1/unit_1/bottleneck_v2/conv2\n",
      "resnet_v2_50/block1/unit_1/bottleneck_v2/conv3\n",
      "resnet_v2_50/block1/unit_1/bottleneck_v2\n",
      "resnet_v2_50/block1/unit_2/bottleneck_v2/conv1\n",
      "resnet_v2_50/block1/unit_2/bottleneck_v2/conv2\n",
      "resnet_v2_50/block1/unit_2/bottleneck_v2/conv3\n",
      "resnet_v2_50/block1/unit_2/bottleneck_v2\n",
      "resnet_v2_50/block1/unit_3/bottleneck_v2/conv1\n",
      "resnet_v2_50/block1/unit_3/bottleneck_v2/conv2\n",
      "resnet_v2_50/block1/unit_3/bottleneck_v2/conv3\n",
      "resnet_v2_50/block1/unit_3/bottleneck_v2\n",
      "resnet_v2_50/block1\n",
      "resnet_v2_50/block2/unit_1/bottleneck_v2/shortcut\n",
      "resnet_v2_50/block2/unit_1/bottleneck_v2/conv1\n",
      "resnet_v2_50/block2/unit_1/bottleneck_v2/conv2\n",
      "resnet_v2_50/block2/unit_1/bottleneck_v2/conv3\n",
      "resnet_v2_50/block2/unit_1/bottleneck_v2\n",
      "resnet_v2_50/block2/unit_2/bottleneck_v2/conv1\n",
      "resnet_v2_50/block2/unit_2/bottleneck_v2/conv2\n",
      "resnet_v2_50/block2/unit_2/bottleneck_v2/conv3\n",
      "resnet_v2_50/block2/unit_2/bottleneck_v2\n",
      "resnet_v2_50/block2/unit_3/bottleneck_v2/conv1\n",
      "resnet_v2_50/block2/unit_3/bottleneck_v2/conv2\n",
      "resnet_v2_50/block2/unit_3/bottleneck_v2/conv3\n",
      "resnet_v2_50/block2/unit_3/bottleneck_v2\n",
      "resnet_v2_50/block2/unit_4/bottleneck_v2/conv1\n",
      "resnet_v2_50/block2/unit_4/bottleneck_v2/conv2\n",
      "resnet_v2_50/block2/unit_4/bottleneck_v2/conv3\n",
      "resnet_v2_50/block2/unit_4/bottleneck_v2\n",
      "resnet_v2_50/block2\n",
      "resnet_v2_50/block3/unit_1/bottleneck_v2/shortcut\n",
      "resnet_v2_50/block3/unit_1/bottleneck_v2/conv1\n",
      "resnet_v2_50/block3/unit_1/bottleneck_v2/conv2\n",
      "resnet_v2_50/block3/unit_1/bottleneck_v2/conv3\n",
      "resnet_v2_50/block3/unit_1/bottleneck_v2\n",
      "resnet_v2_50/block3/unit_2/bottleneck_v2/conv1\n",
      "resnet_v2_50/block3/unit_2/bottleneck_v2/conv2\n",
      "resnet_v2_50/block3/unit_2/bottleneck_v2/conv3\n",
      "resnet_v2_50/block3/unit_2/bottleneck_v2\n",
      "resnet_v2_50/block3/unit_3/bottleneck_v2/conv1\n",
      "resnet_v2_50/block3/unit_3/bottleneck_v2/conv2\n",
      "resnet_v2_50/block3/unit_3/bottleneck_v2/conv3\n",
      "resnet_v2_50/block3/unit_3/bottleneck_v2\n",
      "resnet_v2_50/block3/unit_4/bottleneck_v2/conv1\n",
      "resnet_v2_50/block3/unit_4/bottleneck_v2/conv2\n",
      "resnet_v2_50/block3/unit_4/bottleneck_v2/conv3\n",
      "resnet_v2_50/block3/unit_4/bottleneck_v2\n",
      "resnet_v2_50/block3/unit_5/bottleneck_v2/conv1\n",
      "resnet_v2_50/block3/unit_5/bottleneck_v2/conv2\n",
      "resnet_v2_50/block3/unit_5/bottleneck_v2/conv3\n",
      "resnet_v2_50/block3/unit_5/bottleneck_v2\n",
      "resnet_v2_50/block3/unit_6/bottleneck_v2/conv1\n",
      "resnet_v2_50/block3/unit_6/bottleneck_v2/conv2\n",
      "resnet_v2_50/block3/unit_6/bottleneck_v2/conv3\n",
      "resnet_v2_50/block3/unit_6/bottleneck_v2\n",
      "resnet_v2_50/block3\n",
      "resnet_v2_50/block4/unit_1/bottleneck_v2/shortcut\n",
      "resnet_v2_50/block4/unit_1/bottleneck_v2/conv1\n",
      "resnet_v2_50/block4/unit_1/bottleneck_v2/conv2\n",
      "resnet_v2_50/block4/unit_1/bottleneck_v2/conv3\n",
      "resnet_v2_50/block4/unit_1/bottleneck_v2\n",
      "resnet_v2_50/block4/unit_2/bottleneck_v2/conv1\n",
      "resnet_v2_50/block4/unit_2/bottleneck_v2/conv2\n",
      "resnet_v2_50/block4/unit_2/bottleneck_v2/conv3\n",
      "resnet_v2_50/block4/unit_2/bottleneck_v2\n",
      "resnet_v2_50/block4/unit_3/bottleneck_v2/conv1\n",
      "resnet_v2_50/block4/unit_3/bottleneck_v2/conv2\n",
      "resnet_v2_50/block4/unit_3/bottleneck_v2/conv3\n",
      "resnet_v2_50/block4/unit_3/bottleneck_v2\n",
      "resnet_v2_50/block4\n",
      "resnet_v2_50/logits\n",
      "predictions\n"
     ]
    }
   ],
   "source": [
    "for k in endpoints.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"resnet_v2_50/conv1/BiasAdd:0\", shape=(10, 113, 113, 64), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block1/unit_1/bottleneck_v2/shortcut/BiasAdd:0\", shape=(10, 57, 57, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block1/unit_1/bottleneck_v2/conv1/Relu:0\", shape=(10, 57, 57, 64), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block1/unit_1/bottleneck_v2/conv2/Relu:0\", shape=(10, 57, 57, 64), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block1/unit_1/bottleneck_v2/conv3/BiasAdd:0\", shape=(10, 57, 57, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block1/unit_1/bottleneck_v2/add:0\", shape=(10, 57, 57, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block1/unit_2/bottleneck_v2/conv1/Relu:0\", shape=(10, 57, 57, 64), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block1/unit_2/bottleneck_v2/conv2/Relu:0\", shape=(10, 57, 57, 64), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block1/unit_2/bottleneck_v2/conv3/BiasAdd:0\", shape=(10, 57, 57, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block1/unit_2/bottleneck_v2/add:0\", shape=(10, 57, 57, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block1/unit_3/bottleneck_v2/conv1/Relu:0\", shape=(10, 57, 57, 64), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block1/unit_3/bottleneck_v2/conv2/Relu:0\", shape=(10, 29, 29, 64), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block1/unit_3/bottleneck_v2/conv3/BiasAdd:0\", shape=(10, 29, 29, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block1/unit_3/bottleneck_v2/add:0\", shape=(10, 29, 29, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block1/unit_3/bottleneck_v2/add:0\", shape=(10, 29, 29, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_1/bottleneck_v2/shortcut/BiasAdd:0\", shape=(10, 29, 29, 512), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_1/bottleneck_v2/conv1/Relu:0\", shape=(10, 29, 29, 128), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_1/bottleneck_v2/conv2/Relu:0\", shape=(10, 29, 29, 128), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_1/bottleneck_v2/conv3/BiasAdd:0\", shape=(10, 29, 29, 512), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_1/bottleneck_v2/add:0\", shape=(10, 29, 29, 512), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_2/bottleneck_v2/conv1/Relu:0\", shape=(10, 29, 29, 128), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_2/bottleneck_v2/conv2/Relu:0\", shape=(10, 29, 29, 128), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_2/bottleneck_v2/conv3/BiasAdd:0\", shape=(10, 29, 29, 512), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_2/bottleneck_v2/add:0\", shape=(10, 29, 29, 512), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_3/bottleneck_v2/conv1/Relu:0\", shape=(10, 29, 29, 128), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_3/bottleneck_v2/conv2/Relu:0\", shape=(10, 29, 29, 128), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_3/bottleneck_v2/conv3/BiasAdd:0\", shape=(10, 29, 29, 512), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_3/bottleneck_v2/add:0\", shape=(10, 29, 29, 512), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_4/bottleneck_v2/conv1/Relu:0\", shape=(10, 29, 29, 128), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_4/bottleneck_v2/conv2/Relu:0\", shape=(10, 15, 15, 128), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_4/bottleneck_v2/conv3/BiasAdd:0\", shape=(10, 15, 15, 512), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_4/bottleneck_v2/add:0\", shape=(10, 15, 15, 512), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block2/unit_4/bottleneck_v2/add:0\", shape=(10, 15, 15, 512), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_1/bottleneck_v2/shortcut/BiasAdd:0\", shape=(10, 15, 15, 1024), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_1/bottleneck_v2/conv1/Relu:0\", shape=(10, 15, 15, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_1/bottleneck_v2/conv2/Relu:0\", shape=(10, 15, 15, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_1/bottleneck_v2/conv3/BiasAdd:0\", shape=(10, 15, 15, 1024), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_1/bottleneck_v2/add:0\", shape=(10, 15, 15, 1024), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_2/bottleneck_v2/conv1/Relu:0\", shape=(10, 15, 15, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_2/bottleneck_v2/conv2/Relu:0\", shape=(10, 15, 15, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_2/bottleneck_v2/conv3/BiasAdd:0\", shape=(10, 15, 15, 1024), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_2/bottleneck_v2/add:0\", shape=(10, 15, 15, 1024), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_3/bottleneck_v2/conv1/Relu:0\", shape=(10, 15, 15, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_3/bottleneck_v2/conv2/Relu:0\", shape=(10, 15, 15, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_3/bottleneck_v2/conv3/BiasAdd:0\", shape=(10, 15, 15, 1024), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_3/bottleneck_v2/add:0\", shape=(10, 15, 15, 1024), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_4/bottleneck_v2/conv1/Relu:0\", shape=(10, 15, 15, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_4/bottleneck_v2/conv2/Relu:0\", shape=(10, 15, 15, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_4/bottleneck_v2/conv3/BiasAdd:0\", shape=(10, 15, 15, 1024), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_4/bottleneck_v2/add:0\", shape=(10, 15, 15, 1024), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_5/bottleneck_v2/conv1/Relu:0\", shape=(10, 15, 15, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_5/bottleneck_v2/conv2/Relu:0\", shape=(10, 15, 15, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_5/bottleneck_v2/conv3/BiasAdd:0\", shape=(10, 15, 15, 1024), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_5/bottleneck_v2/add:0\", shape=(10, 15, 15, 1024), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_6/bottleneck_v2/conv1/Relu:0\", shape=(10, 15, 15, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_6/bottleneck_v2/conv2/Relu:0\", shape=(10, 15, 15, 256), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_6/bottleneck_v2/conv3/BiasAdd:0\", shape=(10, 15, 15, 1024), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_6/bottleneck_v2/add:0\", shape=(10, 15, 15, 1024), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block3/unit_6/bottleneck_v2/add:0\", shape=(10, 15, 15, 1024), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block4/unit_1/bottleneck_v2/shortcut/BiasAdd:0\", shape=(10, 15, 15, 2048), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block4/unit_1/bottleneck_v2/conv1/Relu:0\", shape=(10, 15, 15, 512), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block4/unit_1/bottleneck_v2/conv2/Relu:0\", shape=(10, 15, 15, 512), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block4/unit_1/bottleneck_v2/conv3/BiasAdd:0\", shape=(10, 15, 15, 2048), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block4/unit_1/bottleneck_v2/add:0\", shape=(10, 15, 15, 2048), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block4/unit_2/bottleneck_v2/conv1/Relu:0\", shape=(10, 15, 15, 512), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block4/unit_2/bottleneck_v2/conv2/Relu:0\", shape=(10, 15, 15, 512), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block4/unit_2/bottleneck_v2/conv3/BiasAdd:0\", shape=(10, 15, 15, 2048), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block4/unit_2/bottleneck_v2/add:0\", shape=(10, 15, 15, 2048), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block4/unit_3/bottleneck_v2/conv1/Relu:0\", shape=(10, 15, 15, 512), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block4/unit_3/bottleneck_v2/conv2/Relu:0\", shape=(10, 15, 15, 512), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block4/unit_3/bottleneck_v2/conv3/BiasAdd:0\", shape=(10, 15, 15, 2048), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block4/unit_3/bottleneck_v2/add:0\", shape=(10, 15, 15, 2048), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/block4/unit_3/bottleneck_v2/add:0\", shape=(10, 15, 15, 2048), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/logits/BiasAdd:0\", shape=(10, 1, 1, 10), dtype=float32)\n",
      "Tensor(\"resnet_v2_50/predictions/Reshape_1:0\", shape=(10, 1, 1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for k in endpoints.keys():\n",
    "    print(endpoints[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def highestPrimeFactorization(n):    \n",
    "    return [(i, n//i) for i in range(1, int(n**0.5) + 1) if n % i == 0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H,W = highestPrimeFactorization(2048)\n",
    "H,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
