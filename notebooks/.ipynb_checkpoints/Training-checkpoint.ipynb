{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pylab\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "from tensorflow.contrib.layers.python.layers import utils\n",
    "\n",
    "import resnet_v2 as resnet\n",
    "# import cv2\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HourGlass(inputs,scope):\n",
    "    levels_down = {}\n",
    "    levels_up = {}\n",
    "    LEVELS = 5\n",
    "    net = inputs\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        with tf.name_scope(\"DownSample\"):\n",
    "            for i in range(LEVELS):\n",
    "                if i == 0:\n",
    "                    net = tf.layers.conv2d(net,64,(3,3),(2,2),'same',name=\"Conv{}\".format(2*i),activation=tf.nn.relu)\n",
    "                    levels_down[2*i] = net\n",
    "                    net = tf.layers.conv2d(net,64,(3,3),(2,2),'same',name=\"Conv{}\".format(2*i+1),activation=tf.nn.relu)\n",
    "                    levels_down[2*i+1] = net\n",
    "                else:\n",
    "                    net = tf.layers.conv2d(net,32,(3,3),(1,1),'same',name=\"Conv{}\".format(2*i),activation=tf.nn.relu)\n",
    "                    levels_down[2*i] = net\n",
    "                    net = tf.layers.conv2d(net,32,(3,3),(2,2),'same',name=\"Conv{}\".format(2*i+1),activation=tf.nn.relu)\n",
    "                    levels_down[2*i+1] = net\n",
    "        with tf.name_scope(\"Bottleneck\"):\n",
    "            net = tf.layers.conv2d(net,16,(1,1),(1,1),name=\"bottleneck\")\n",
    "\n",
    "        with tf.name_scope(\"UpSample\"):\n",
    "            for i in reversed(range(LEVELS)):\n",
    "                if i != 0:\n",
    "                    net = tf.layers.conv2d_transpose(net,32,(3,3),(2,2),'same',name=\"TransposeConv{}\".format(2*i+1),\n",
    "                                                     activation=tf.nn.relu)\n",
    "                    levels_up[2*i+1] = net\n",
    "                    net = tf.layers.conv2d_transpose(net,32,(3,3),(1,1),'same',name=\"TransposeConv{}\".format(2*i),\n",
    "                                                     activation=tf.nn.relu)\n",
    "                    levels_up[2*i] = net\n",
    "                    net = tf.concat([net, levels_down[2*i]],axis=3)\n",
    "                else:\n",
    "                    net = tf.layers.conv2d_transpose(net,16,(3,3),(2,2),'same',name=\"TransposeConv{}\".format(2*i+1),\n",
    "                                                     activation=tf.nn.relu)\n",
    "                    levels_up[2*i+1] = net\n",
    "#                     net = tf.layers.conv2d_transpose(net,16,(3,3),(2,2),'same',name=\"TransposeConv{}\".format(2*i),\n",
    "#                                                      activation=tf.nn.relu)\n",
    "#                     levels_up[2*i] = net\n",
    "                    \n",
    "    return net, levels_down, levels_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keypoint_CrossEntropyLoss(prediction_maps, keypoint_masks, labels, L=5.0, scope=\"keypointLoss\"):\n",
    "    \"\"\"\n",
    "    heat_maps = predictions from network\n",
    "    keypoints (N,17,2) = actual keypoint locations\n",
    "    labels (N,17,1) = 0 if invalid, 1 if occluded, 2 if valid\n",
    "    \"\"\"\n",
    "    losses = tf.nn.sigmoid_cross_entropy_with_logits(logits=prediction_maps,labels=keypoint_masks)\n",
    "    labels = tf.reshape(labels,[-1,1,1,17])\n",
    "    losses = tf.multiply(losses,labels) # set loss to zero for invalid keypoints (labels=0)\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keypoint_SquaredErrorLoss(prediction_maps, keypoint_masks, labels, L=5.0, scope=\"keypointLoss\"):\n",
    "    \"\"\"\n",
    "    heat_maps = predictions from network\n",
    "    keypoints (N,17,2) = actual keypoint locations\n",
    "    labels (N,17,1) = 0 if invalid, 1 if occluded, 2 if valid\n",
    "    \"\"\"\n",
    "    losses = tf.squared_difference(prediction_maps,keypoint_masks)\n",
    "    labels = tf.reshape(labels,[-1,1,1,17])\n",
    "    losses = tf.multiply(losses,labels) # set loss to zero for invalid keypoints (labels=0)\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=10.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "def get_data(base_dir,image_dir,ann_file):\n",
    "    image_path = '{}/images/{}'.format(baseDir,image_dir)\n",
    "    ann_path='{}/annotations/{}.json'.format(baseDir,ann_file)\n",
    "\n",
    "    return image_path, ann_path\n",
    "    \n",
    "# define the path to the annotation file corresponding to the images you want to work with\n",
    "baseDir='/Users/kyle/Repositories/coco'\n",
    "\n",
    "trainData='person_keypoints_train2014'\n",
    "valData='person_keypoints_val2014'\n",
    "testData='image_info_test-dev2015'\n",
    "\n",
    "imageTrainDir = 'train2014'\n",
    "imageValDir = 'val2014'\n",
    "imageTestDir = 'test2015'\n",
    "\n",
    "train_img_path, train_ann_path = get_data(baseDir,imageTrainDir,trainData)\n",
    "val_img_path, val_ann_path = get_data(baseDir,imageValDir,valData)\n",
    "\n",
    "# initialize a coco object\n",
    "coco = COCO(train_ann_path)\n",
    "\n",
    "# get all images containing the 'person' category\n",
    "catIds = coco.getCatIds(catNms=['person'])\n",
    "imgIds = coco.getImgIds(catIds=catIds)\n",
    "\n",
    "# Just for dealing with the images on my computer (not necessary when working with the whole dataset)\n",
    "catIds = imgIds[0:30]\n",
    "imgIds = imgIds[0:30]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    VGG_MEAN = tf.reshape(tf.constant([123.68, 116.78, 103.94]),[1,1,3])\n",
    "    NUM_KEYPOINTS = 17\n",
    "    BATCH_SIZE = 10\n",
    "    L = 10.0 # keypoint effective radius\n",
    "    \n",
    "    def extract_annotations(filename, imgID, coco=coco):\n",
    "        anns = coco.loadAnns(coco.getAnnIds(imgID,catIds=[1],iscrowd=None))\n",
    "        ann = max([ann for ann in anns], key=lambda item:item['area']) # extract annotation for biggest instance\n",
    "        bbox = np.array(np.floor(ann['bbox']),dtype=int)\n",
    "        keypoints = np.reshape(ann['keypoints'],(-1,3))\n",
    "        mask = coco.annToMask(ann)\n",
    "        \n",
    "        return filename, bbox, keypoints, mask\n",
    "    \n",
    "    def preprocess_image_tf(filename, bbox_tensor, keypoints_tensor, mask, D = tf.constant(256.0)):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        resized_image (N,D,D,3) - cropped, padded (if needed), scaled to square image of size D\n",
    "        resized_mask (N,D,D,1) - cropped, padded (if needed), scaled to square mask of size D\n",
    "        pts (N,2,17) - keypoint coordinates (i,j) scaled to match up with resized_image\n",
    "        labels (N,1,17) - values corresponding to pts: {0: invalid, 1:occluded, 2:valid}\n",
    "        \"\"\"\n",
    "        image_string = tf.read_file(filename)\n",
    "        image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "        image = tf.cast(image_decoded, tf.float32)\n",
    "\n",
    "        mask = tf.transpose([mask],[1,2,0])\n",
    "        bbox_tensor = tf.to_float(bbox_tensor)\n",
    "        keypoints_tensor = tf.to_float(keypoints_tensor)\n",
    "\n",
    "        sideLength = tf.reduce_max(bbox_tensor[2:],axis=0)\n",
    "        centerX = tf.floor(bbox_tensor[0] + tf.divide(bbox_tensor[2],tf.constant(2.0)))\n",
    "        centerY = tf.floor(bbox_tensor[1] + tf.divide(bbox_tensor[3],tf.constant(2.0)))\n",
    "        center = tf.stack([centerX,centerY])\n",
    "\n",
    "        corner1 = tf.to_int32(tf.minimum(tf.maximum(tf.subtract(center, tf.divide(sideLength,tf.constant(2.0))),0),\n",
    "                             tf.reverse(tf.to_float(tf.shape(image)[:2]),tf.constant([0]))))\n",
    "        corner2 = tf.to_int32(tf.minimum(tf.maximum(tf.add(center, tf.divide(sideLength,tf.constant(2.0))),0),\n",
    "                             tf.reverse(tf.to_float(tf.shape(image)[:2]),tf.constant([0]))))\n",
    "        i_shape = tf.subtract(corner2,corner1)\n",
    "        d_shape = tf.subtract(tf.to_int32(sideLength),i_shape)\n",
    "\n",
    "        scale = tf.divide(D, sideLength)\n",
    "        cropped_image = tf.image.crop_to_bounding_box(image,corner1[1],corner1[0],\n",
    "                                                      tf.subtract(corner2,corner1)[1],tf.subtract(corner2,corner1)[0])\n",
    "        cropped_mask = tf.image.crop_to_bounding_box(mask,corner1[1],corner1[0],\n",
    "                                                      tf.subtract(corner2,corner1)[1],tf.subtract(corner2,corner1)[0])\n",
    "\n",
    "        dX = tf.floor(tf.divide(d_shape,tf.constant(2)))\n",
    "        dY = tf.ceil(tf.divide(d_shape,tf.constant(2)))\n",
    "\n",
    "        pts, labels = tf.split(keypoints_tensor,[2,1],axis=1)\n",
    "        pts = tf.subtract(pts,tf.to_float(corner1)) # shift keypoints\n",
    "        pts = tf.add(pts,tf.to_float(dX)) # shift keypoints\n",
    "        pts = tf.multiply(pts,scale) # scale keypoints\n",
    "\n",
    "        # set invalid pts to 0\n",
    "        inbounds = tf.less(pts,D)\n",
    "        inbounds = tf.multiply(tf.to_int32(inbounds), tf.to_int32(tf.greater(pts,0)))\n",
    "        pts = tf.multiply(pts,tf.to_float(inbounds))\n",
    "        pts = tf.transpose(pts,[1,0])\n",
    "        labels = tf.transpose(labels,[1,0])\n",
    "\n",
    "        padded_image = tf.image.pad_to_bounding_box(cropped_image,tf.to_int32(dX[1]),tf.to_int32(dX[0]),\n",
    "                                                    tf.to_int32(sideLength),tf.to_int32(sideLength))\n",
    "        padded_mask = tf.image.pad_to_bounding_box(cropped_mask,tf.to_int32(dX[1]),tf.to_int32(dX[0]),\n",
    "                                                    tf.to_int32(sideLength),tf.to_int32(sideLength))\n",
    "\n",
    "        resized_image = tf.image.resize_images(padded_image,tf.constant([256,256]),tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        resized_image = resized_image - VGG_MEAN\n",
    "        resized_mask = tf.image.resize_images(padded_mask,tf.constant([256,256]),tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        return resized_image, resized_mask, pts, labels\n",
    "\n",
    "    def scaleDownMaskAndKeypoints(image, mask, pts, labels):\n",
    "        mask = tf.image.resize_images(mask,tf.constant([128,128]),tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        pts = tf.multiply(pts,tf.constant(0.5))\n",
    "        return image, mask, pts, labels\n",
    "    \n",
    "    def generate_keypoint_masks(image, mask, keypoints, labels, D=128.0, L=L):\n",
    "        X, Y = tf.meshgrid(tf.linspace(0.0,128.0,128),tf.linspace(0.0,128.0,128))\n",
    "        X = tf.reshape(X,[128,128,1])\n",
    "        Y = tf.reshape(Y,[128,128,1])\n",
    "        X_stack = tf.tile(X,tf.constant([1,1,17],dtype=tf.int32))\n",
    "        Y_stack = tf.tile(Y,tf.constant([1,1,17],dtype=tf.int32))\n",
    "\n",
    "        pts = tf.reshape(keypoints,[1,2,17])\n",
    "        ptsX, ptsY = tf.split(pts,[1,1],axis=1)\n",
    "        d1 = tf.square(tf.subtract(X_stack,ptsX))\n",
    "        d2 = tf.square(tf.subtract(Y_stack,ptsY))\n",
    "\n",
    "        pt_masks = tf.multiply(tf.divide(tf.constant(1.0),tf.add(d1,d2)+L),L)\n",
    "        return image, mask, pt_masks, pts, labels\n",
    "    \n",
    "    ########## DATASET ###########\n",
    "    \n",
    "    with tf.variable_scope(\"DataSet\"):\n",
    "        # Initialize train_dataset\n",
    "        filenames = tf.constant(['{}/COCO_train2014_{:0>12}.jpg'.format(train_img_path,imgID) for imgID in imgIds])\n",
    "        imgID_tensor = tf.constant(imgIds)\n",
    "\n",
    "        train_dataset = tf.contrib.data.Dataset.from_tensor_slices((filenames,imgID_tensor))\n",
    "        # Extract Annotations via coco interface\n",
    "        train_dataset = train_dataset.map(lambda filename, imgID: tf.py_func(extract_annotations, [filename, imgID], \n",
    "                                                                     [filename.dtype, tf.int64, tf.int64, tf.uint8]))\n",
    "        # All other preprocessing in tensorflow\n",
    "        train_dataset = train_dataset.map(preprocess_image_tf)\n",
    "        train_dataset = train_dataset.map(scaleDownMaskAndKeypoints)\n",
    "        train_dataset = train_dataset.map(generate_keypoint_masks)\n",
    "\n",
    "        # BATCH\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "        train_dataset = train_dataset.batch(10) # must resize images to make them match\n",
    "        iterator = tf.contrib.data.Iterator.from_structure(train_dataset.output_types,train_dataset.output_shapes)\n",
    "        # resized_image, resized_mask, pts, labels = iterator.get_next()\n",
    "#         images, masks, pts, labels = iterator.get_next()\n",
    "        images, masks, kpt_masks, pts, labels = iterator.get_next()\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "    \n",
    "    with tf.variable_scope(\"KyleNet\") as sc:\n",
    "        backbone, levels_down, levels_up = HourGlass(images,sc)\n",
    "        \n",
    "        with tf.variable_scope(\"MaskLoss\"):\n",
    "            maskPrediction = tf.layers.conv2d(backbone,1,(3,3),(1,1),'same',name='MaskPred')\n",
    "            maskError = tf.nn.sigmoid_cross_entropy_with_logits(logits=maskPrediction,labels=tf.to_float(masks))\n",
    "            maskLoss = tf.reduce_sum(maskError)\n",
    "        \n",
    "        with tf.variable_scope(\"KeypointLoss\") as sc2:\n",
    "            keypointPredictions = tf.layers.conv2d(backbone,NUM_KEYPOINTS,(3,3),(1,1),'same',name='KeypointPreds')\n",
    "            keypointLoss = keypoint_CrossEntropyLoss(keypointPredictions,kpt_masks,labels,scope=sc2)\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        file_writer = tf.summary.FileWriter('/tmp/HourGlassNet/1')\n",
    "        file_writer.add_graph(sess.graph)\n",
    "        \n",
    "        # initialize variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # initialize dataset\n",
    "        sess.run(train_init_op) \n",
    "        masks, kpt_masks, mask_pred, kpt_pred, mask_loss, kpt_loss = sess.run([masks, kpt_masks, maskPrediction, \n",
    "                                                             keypointPredictions, maskLoss, keypointLoss])\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 3\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(mask_pred[i][:,:,0])\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(kpt_pred[i][:,:,0])\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(masks[i][:,:,0])\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(np.sum(kpt_masks[i],axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init_fn(sess)  # load the pretrained weights\n",
    "# sess.run(fc8_init)  # initialize the new fc8 layer\n",
    "sess.run(train_init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# resized_image, resized_mask, pts, labels = sess.run(next_element)\n",
    "\n",
    "try:\n",
    "    I, M, P, L = sess.run([images, masks, pts, labels], {is_training: True})\n",
    "    plt.imshow(I[0])\n",
    "    plt.imshow(M[0][:,:,0],alpha=0.5)\n",
    "    plt.scatter(P[0][(np.reshape(L[0],-1)==2),0],P[0][(np.reshape(L[0],-1)==2),1],c=\"r\")\n",
    "except tf.errors.OutOfRangeError:\n",
    "    sess.run(train_init_op)\n",
    "    print(\"Reinitialized Dataset Iterator...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
