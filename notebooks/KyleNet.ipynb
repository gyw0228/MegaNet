{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pylab\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "from tensorflow.contrib.layers.python.layers import utils\n",
    "\n",
    "import resnet_v2 as resnet\n",
    "# import cv2\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing COCO objects to extract training and validation datasets...\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=12.17s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=7.29s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "def get_data(base_dir,image_dir,ann_file):\n",
    "    image_path = '{}/images/{}'.format(baseDir,image_dir)\n",
    "    ann_path='{}/annotations/{}.json'.format(baseDir,ann_file)\n",
    "\n",
    "    return image_path, ann_path\n",
    "    \n",
    "# define the path to the annotation file corresponding to the images you want to work with\n",
    "baseDir='/Users/kyle/Repositories/coco'\n",
    "\n",
    "trainData='person_keypoints_train2014'\n",
    "valData='person_keypoints_val2014'\n",
    "testData='image_info_test-dev2015'\n",
    "\n",
    "imageTrainDir = 'train2014'\n",
    "imageValDir = 'val2014'\n",
    "imageTestDir = 'test2015'\n",
    "\n",
    "train_img_path, train_ann_path = get_data(baseDir,imageTrainDir,trainData)\n",
    "val_img_path, val_ann_path = get_data(baseDir,imageValDir,valData)\n",
    "# initialize a coco object\n",
    "print(\"Initializing COCO objects to extract training and validation datasets...\\n\")\n",
    "train_coco = COCO(train_ann_path)\n",
    "val_coco = COCO(val_ann_path)\n",
    "# get all images containing the 'person' category\n",
    "train_catIds = train_coco.getCatIds(catNms=['person'])\n",
    "train_imgIds = train_coco.getImgIds(catIds=train_catIds)\n",
    "val_catIds = val_coco.getCatIds(catNms=['person'])\n",
    "val_imgIds = val_coco.getImgIds(catIds=val_catIds)\n",
    "# Just for dealing with the images on my computer (not necessary when working with the whole dataset)\n",
    "# if args.small_dataset:\n",
    "train_catIds = train_catIds[0:30]\n",
    "train_imgIds = train_imgIds[0:30]\n",
    "val_catIds = val_catIds[0:30]\n",
    "val_imgIds = val_imgIds[0:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "############### VARIOUS HYPER-PARAMETERS ##############\n",
    "#######################################################\n",
    "\n",
    "NUM_KEYPOINTS = 17\n",
    "BATCH_SIZE = 5 #args.batch_size\n",
    "L = 5.0 # keypoint effective radius\n",
    "D = 224 # image height and width\n",
    "d = 56 # evaluation height and width (for mask and keypoint masks)\n",
    "\n",
    "MASK_THRESHOLD = 0.5 # threshold for on/off prediction (in mask and keypoint masks)\n",
    "KP_THRESHOLD = 0.5 # threshold for on/off prediction (in mask and keypoint masks)\n",
    "KP_DISTANCE_THRESHOLD = 5.0 # threshold for determining if a keypoint estimate is accurate\n",
    "X_INIT = tf.contrib.layers.xavier_initializer_conv2d() # xavier initializer for head architecture\n",
    "# learning_rate1 = args.learning_rate1\n",
    "# learning_rate2 = args.learning_rate2\n",
    "\n",
    "#######################################################\n",
    "#### VISUALIZATION TOOLS - WEIGHTS AND ACTIVATIONS ####\n",
    "#######################################################\n",
    "def highestPrimeFactorization(n):    \n",
    "    return [(i, n//i) for i in range(1, int(n**0.5) + 1) if n % i == 0][-1] \n",
    "\n",
    "def getFilterImage(filters):\n",
    "    \"\"\"\n",
    "    Takes as input a filter bank of size (1, H, W, C, D)\n",
    "    Returns: a tensor of size (1, sqrt(D)*H, sqrt(D)*H, C)\n",
    "    (This only really works for the first layer of filtes with an image as input)\n",
    "    \"\"\"\n",
    "    padded_filters = tf.pad(filters,tf.constant([[0,0],[1,0],[1,0],[0,0],[0,0]]),'CONSTANT')\n",
    "    filter_list = tf.unstack(padded_filters,axis=4)\n",
    "    H,W = highestPrimeFactorization(len(filter_list))\n",
    "    weight_strips = [tf.concat(filter_list[8*i:8*(i+1)],axis=1) for i in range(W)]\n",
    "    weight_image = tf.concat(weight_strips,axis=2)\n",
    "    return weight_image\n",
    "\n",
    "def getActivationImage(activations):\n",
    "    \"\"\"\n",
    "    Tiles an activation map into a square grayscale image\n",
    "    Takes as input an activation map of size (N, H, W, D)\n",
    "    Returns: a tensor of size (N, sqrt(D)*H, sqrt(D)*H, 1)\n",
    "    \"\"\"\n",
    "    padded_activations = tf.pad(activations,tf.constant([[0,0],[1,0],[1,0],[0,0]]),'CONSTANT')\n",
    "    expanded_activations = tf.expand_dims(padded_activations,axis=3)\n",
    "    activations_list = tf.unstack(expanded_activations,axis=4)\n",
    "    H,W = highestPrimeFactorization(len(activations_list))\n",
    "    activation_strips = [tf.concat(activations_list[H*i:H*(i+1)],axis=1) for i in range(W)]\n",
    "    activation_image = tf.concat(activation_strips,axis=2)\n",
    "    return activation_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "##### PRE-PROCESSING AND DATASET EXTRACTION TOOLS #####\n",
    "#######################################################\n",
    "def extract_annotations_train(filename, imgID, coco=train_coco):\n",
    "    anns = coco.loadAnns(coco.getAnnIds(imgID,catIds=[1],iscrowd=None))\n",
    "    ann = max([ann for ann in anns], key=lambda item:item['area']) # extract annotation for biggest instance\n",
    "    bbox = np.array(np.floor(ann['bbox']),dtype=int)\n",
    "    keypoints = np.reshape(ann['keypoints'],(-1,3))\n",
    "    mask = coco.annToMask(ann)\n",
    "\n",
    "    return filename, bbox, keypoints, mask\n",
    "\n",
    "def extract_annotations_val(filename, imgID, coco=val_coco):\n",
    "    anns = coco.loadAnns(coco.getAnnIds(imgID,catIds=[1],iscrowd=None))\n",
    "    ann = max([ann for ann in anns], key=lambda item:item['area']) # extract annotation for biggest instance\n",
    "    bbox = np.array(np.floor(ann['bbox']),dtype=int)\n",
    "    keypoints = np.reshape(ann['keypoints'],(-1,3))\n",
    "    mask = coco.annToMask(ann)\n",
    "\n",
    "    return filename, bbox, keypoints, mask\n",
    "\n",
    "def preprocess_image_tf(filename, bbox_tensor, keypoints_tensor, mask, D=D):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    resized_image (N,D,D,3) - cropped, scaled to square image of size D\n",
    "    resized_mask (N,D,D,1) - cropped, scaled to square mask of size D\n",
    "    pts (N,2,17) - keypoint coordinates (i,j) scaled to match up with resized_image\n",
    "    labels (N,1,17) - values corresponding to pts: {0: invalid, 1:occluded, 2:valid}\n",
    "    \"\"\"\n",
    "    image_string = tf.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.cast(image_decoded, tf.float32)\n",
    "\n",
    "    # subtract mean\n",
    "    image = tf.subtract(image, tf.reduce_mean(image))\n",
    "\n",
    "    mask = tf.transpose([mask],[1,2,0])\n",
    "    bbox_tensor = tf.to_float(bbox_tensor)\n",
    "    keypoints_tensor = tf.to_float(keypoints_tensor)\n",
    "\n",
    "    sideLength = tf.reduce_max(bbox_tensor[2:],axis=0)\n",
    "    centerX = tf.floor(bbox_tensor[0] + tf.divide(bbox_tensor[2],tf.constant(2.0)))\n",
    "    centerY = tf.floor(bbox_tensor[1] + tf.divide(bbox_tensor[3],tf.constant(2.0)))\n",
    "    center = tf.stack([centerX,centerY])\n",
    "\n",
    "    corner1 = tf.to_int32(tf.minimum(tf.maximum(tf.subtract(center, tf.divide(sideLength,tf.constant(2.0))),0),\n",
    "                        tf.reverse(tf.to_float(tf.shape(image)[:2]),tf.constant([0]))))\n",
    "    corner2 = tf.to_int32(tf.minimum(tf.maximum(tf.add(center, tf.divide(sideLength,tf.constant(2.0))),0),\n",
    "                        tf.reverse(tf.to_float(tf.shape(image)[:2]),tf.constant([0]))))\n",
    "    i_shape = tf.subtract(corner2,corner1)\n",
    "    ##### Move corner 2 to enforce squareness!! #####\n",
    "    corner2 = corner1 + tf.reduce_min(i_shape)\n",
    "    sideLength = tf.to_float(tf.reduce_min(corner2-corner1))\n",
    "\n",
    "    scale = tf.divide(tf.constant(D,tf.float32), sideLength)\n",
    "    cropped_image = tf.image.crop_to_bounding_box(image,corner1[1],corner1[0],\n",
    "                                                tf.subtract(corner2,corner1)[1],tf.subtract(corner2,corner1)[0])\n",
    "    cropped_mask = tf.image.crop_to_bounding_box(mask,corner1[1],corner1[0],\n",
    "                                                tf.subtract(corner2,corner1)[1],tf.subtract(corner2,corner1)[0])\n",
    "\n",
    "    pts, labels = tf.split(keypoints_tensor,[2,1],axis=1)\n",
    "    pts = tf.subtract(pts,tf.to_float(corner1)) # shift keypoints\n",
    "    pts = tf.multiply(pts,scale) # scale keypoints\n",
    "\n",
    "    # set invalid pts to 0\n",
    "    valid = tf.less(pts,tf.constant(D,tf.float32))\n",
    "    valid = tf.reduce_min(tf.multiply(tf.to_float(valid), tf.to_float(tf.greater(pts,0))), axis=1, keep_dims=True)\n",
    "    pts = tf.multiply(pts,valid)\n",
    "    labels = tf.multiply(labels,valid)\n",
    "    pts = tf.transpose(pts,[1,0])\n",
    "    labels = tf.transpose(labels,[1,0])\n",
    "    labels = tf.to_float(tf.greater_equal(labels, 1.5)) # only use labels whose values are 2 - is this a good idea?\n",
    "\n",
    "    resized_image = tf.image.resize_images(cropped_image,tf.constant([D,D]),tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    resized_mask = tf.image.resize_images(cropped_mask,tf.constant([D,D]),tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    return resized_image, resized_mask, pts, labels\n",
    "\n",
    "def scaleDownMaskAndKeypoints(image, mask, pts, labels, d=d, D=D):\n",
    "    mask = tf.image.resize_images(mask,tf.constant([d,d]),tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    pts = tf.multiply(pts,tf.constant(d/D))\n",
    "    return image, mask, pts, labels\n",
    "\n",
    "def generate_keypoint_masks(image, mask, keypoints, labels, d=d, D=D, L=L):\n",
    "    X, Y = tf.meshgrid(tf.linspace(0.0,d,d),tf.linspace(0.0,d,d))\n",
    "    X = tf.reshape(X,[d,d,1])\n",
    "    Y = tf.reshape(Y,[d,d,1])\n",
    "    X_stack = tf.tile(X,tf.constant([1,1,17],dtype=tf.int32))\n",
    "    Y_stack = tf.tile(Y,tf.constant([1,1,17],dtype=tf.int32))\n",
    "\n",
    "    pts = tf.reshape(keypoints,[1,2,17])\n",
    "    ptsX, ptsY = tf.split(pts,[1,1],axis=1)\n",
    "    d1 = tf.square(tf.subtract(X_stack,ptsX))\n",
    "    d2 = tf.square(tf.subtract(Y_stack,ptsY))\n",
    "\n",
    "    pt_masks = tf.multiply(tf.divide(tf.constant(1.0),tf.add(d1,d2)+L),L)\n",
    "    return image, mask, pt_masks, pts, labels\n",
    "def generate_one_hot_keypoint_masks(image, mask, keypoints, labels, d=d):\n",
    "    pts = tf.reshape(keypoints,[1,2,17])\n",
    "    indices = tf.to_int32(pts)\n",
    "    kp_mask1 = tf.one_hot(depth=d,indices=indices[:,1,:],axis=0)\n",
    "    kp_mask2 = tf.one_hot(depth=d,indices=indices[:,0,:],axis=1)\n",
    "    kp_masks = tf.matmul(tf.transpose(kp_mask1,(2,0,1)),tf.transpose(kp_mask2,(2,0,1)))\n",
    "    kp_masks = tf.transpose(kp_masks,(1,2,0))\n",
    "    return image, mask, kp_masks, pts, labels\n",
    "\n",
    "\n",
    "def softmax_keypoint_masks(kpt_masks, d=d):\n",
    "    return tf.reshape(tf.nn.softmax(tf.reshape(kpt_masks, [-1,d**2,17]),dim=1),[-1,d,d,17])\n",
    "def bilinear_filter(channels_in,channels_out):\n",
    "    f = tf.multiply(tf.constant([0.5, 1.0, 0.5],shape=[3,1]),tf.constant([0.5, 1.0, 0.5],shape=[1,3]))\n",
    "    f = tf.stack([f for i in range(channels_out)],axis=2)\n",
    "    f = tf.stack([f for i in range(channels_in)],axis=3)\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get all images containing the 'person' category\n",
    "train_catIds = train_coco.getCatIds(catNms=['person'])\n",
    "train_imgIds = train_coco.getImgIds(catIds=train_catIds)\n",
    "val_catIds = val_coco.getCatIds(catNms=['person'])\n",
    "val_imgIds = val_coco.getImgIds(catIds=val_catIds)\n",
    "\n",
    "# Just for dealing with the images on my computer (not necessary when working with the whole dataset)\n",
    "# if args.small_dataset == True:\n",
    "train_catIds = train_catIds[0:30]\n",
    "train_imgIds = train_imgIds[0:30]\n",
    "val_catIds = val_catIds[0:30]\n",
    "val_imgIds = val_imgIds[0:30]\n",
    "\n",
    "################### TRAIN DATASET ###################\n",
    "train_filenames = tf.constant(['{}/COCO_train2014_{:0>12}.jpg'.format(train_img_path, imgID) for imgID in train_imgIds])\n",
    "train_imgID_tensor = tf.constant(train_imgIds)\n",
    "train_dataset = tf.contrib.data.Dataset.from_tensor_slices((train_filenames, train_imgID_tensor))\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda filename, imgID: tf.py_func(extract_annotations_train, [filename, imgID], [filename.dtype, tf.int64, tf.int64, tf.uint8]))\n",
    "train_dataset = train_dataset.map(preprocess_image_tf)\n",
    "train_dataset = train_dataset.map(scaleDownMaskAndKeypoints)\n",
    "train_dataset = train_dataset.map(generate_one_hot_keypoint_masks)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "#################### VAL DATASET ####################\n",
    "val_filenames = tf.constant(['{}/COCO_val2014_{:0>12}.jpg'.format(val_img_path, imgID) for imgID in val_imgIds])\n",
    "val_imgID_tensor = tf.constant(val_imgIds)\n",
    "val_dataset = tf.contrib.data.Dataset.from_tensor_slices((val_filenames, val_imgID_tensor))\n",
    "val_dataset = val_dataset.map(\n",
    "    lambda filename, imgID: tf.py_func(extract_annotations_val,[filename, imgID],[filename.dtype, tf.int64, tf.int64, tf.uint8]))\n",
    "val_dataset = val_dataset.map(preprocess_image_tf)\n",
    "val_dataset = val_dataset.map(scaleDownMaskAndKeypoints)\n",
    "val_dataset = val_dataset.map(generate_one_hot_keypoint_masks)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=10000)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "iterator = tf.contrib.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "\n",
    "images, masks, kpt_masks, pts, labels = iterator.get_next()\n",
    "train_init_op = iterator.make_initializer(train_dataset)\n",
    "val_init_op = iterator.make_initializer(val_dataset)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax with all zeros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(train_init_op)\n",
    "I,M,KPM,KP,L = sess.run([images, masks, kpt_masks, pts, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_maps = tf.ones_like(kpt_masks)\n",
    "# prediction_maps = tf.random_normal(kpt_masks[0].shape)\n",
    "# prediction_maps = kpt_masks[0]\n",
    "\n",
    "keypoint_masks = kpt_masks\n",
    "\n",
    "map_shape = prediction_maps.shape.as_list()\n",
    "flat_shape = (-1,1,map_shape[1]*map_shape[2],map_shape[3])\n",
    "pred_flat = tf.reshape(prediction_maps, flat_shape)\n",
    "masks_flat = tf.reshape(keypoint_masks, flat_shape)\n",
    "# softmax over dimension 1\n",
    "losses1 = tf.nn.softmax_cross_entropy_with_logits(labels=masks_flat,logits=pred_flat,dim=0)\n",
    "losses2 = tf.nn.softmax_cross_entropy_with_logits(labels=masks_flat,logits=pred_flat,dim=1)\n",
    "losses3 = tf.nn.softmax_cross_entropy_with_logits(labels=masks_flat,logits=pred_flat,dim=2)\n",
    "labels = tf.reshape(labels,[-1,1,17])\n",
    "losses = tf.multiply(losses3,labels) # set loss to zero for invalid keypoints (labels=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(train_init_op)\n",
    "L1, L2, L3, LA, L, I, KPM, P = sess.run([losses1, losses2, losses3, labels, losses, images, kpt_masks, pts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 3136, 17), (5, 3136, 17), (5, 1, 17), (5, 1, 17), (5, 1, 17))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1.shape, L2.shape, L3.shape, LA.shape, L.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 8.05070305,  8.05070305,  8.05070305,  8.05070305,  8.05070305,\n",
       "          8.05070305,  8.05070305,  8.05070305,  8.05070305,  8.05070305,\n",
       "          8.05070305,  8.05070305,  8.05070305,  8.05070305,  8.05070305,\n",
       "          8.05070305,  8.05070305]], dtype=float32),\n",
       " array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.]], dtype=float32),\n",
       " array([[[-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "          -0., -0., -0., -0.],\n",
       "         [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "          -0., -0., -0., -0.]]], dtype=float32))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAEgCAYAAABsCt3QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiKKCA+0iIiIiCLyPwZuY6bZbzO3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e460710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 1\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(I[i])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(np.sum(KPM[i],axis=2)*255,cmap=\"hot\")\n",
    "L3[i],L[i],P[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(L1), np.sum(L2) #, np.sum(L3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(L1 != 0), np.sum(L2 != 0), np.sum(L3 != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = tf.random_normal([1,10])\n",
    "labels = tf.zeros_like(logits)\n",
    "sft = tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels,dim=0)\n",
    "sft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_keypoint_masks(kpt_masks, d=56):\n",
    "    return tf.reshape(tf.nn.softmax(tf.reshape(kpt_masks, [-1,d**2,17]),dim=1),[-1,d,d,17])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Square tiling (rather than prime factorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def highestPrimeFactorization(n):    \n",
    "    return [(i, n//i) for i in range(1, int(n**0.5) + 1) if n % i == 0][-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFilterImage(filters):\n",
    "    \"\"\"\n",
    "    Takes as input a filter bank of size (1, H, W, C, D)\n",
    "    Returns: a tensor of size (1, sqrt(D)*H, sqrt(D)*H, C)\n",
    "    (This only really works for the first layer of filters with an image as input)\n",
    "    \"\"\"\n",
    "    padded_filters = tf.pad(filters,tf.constant([[0,0],[1,0],[1,0],[0,0],[0,0]]),'CONSTANT')\n",
    "    filter_list = tf.unstack(padded_filters,axis=4)\n",
    "    N = len(filter_list)\n",
    "    H = int(np.ceil(np.sqrt(N)))\n",
    "    W = int(np.floor(N/H))\n",
    "    diff = N - H*W\n",
    "    weight_strips = [tf.concat(filter_list[H*i:H*(i+1)],axis=1) for i in range(W)]\n",
    "    if diff > 0:\n",
    "        final_strip = tf.concat(filter_list[H*W:N],axis=1)\n",
    "        final_strip = tf.pad(final_strip,tf.constant([[0,0],[0,(H-diff)*padded_filters.shape.as_list()[1]],[0,0],[0,0]]),'CONSTANT')\n",
    "        weight_strips.append(final_strip)\n",
    "    weight_image = tf.concat(weight_strips,axis=2)\n",
    "    \n",
    "    return weight_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getActivationImage(activations, scale_up=False):\n",
    "    \"\"\"\n",
    "    Tiles an activation map into a square grayscale image\n",
    "    Takes as input an activation map of size (N, H, W, D)\n",
    "    Returns: a tensor of size (N, sqrt(D)*H, sqrt(D)*H, 1)\n",
    "    \"\"\"\n",
    "    padded_activations = tf.pad(activations,tf.constant([[0,0],[1,0],[1,0],[0,0]]),'CONSTANT')\n",
    "    expanded_activations = tf.expand_dims(padded_activations,axis=3)\n",
    "    activations_list = tf.unstack(expanded_activations,axis=4)\n",
    "    N = len(activations_list)\n",
    "    H = int(np.ceil(np.sqrt(N)))\n",
    "    W = int(np.floor(N/H))\n",
    "    diff = N - H*W\n",
    "    activation_strips = [tf.concat(activations_list[H*i:H*(i+1)],axis=1) for i in range(W)]\n",
    "    if diff > 0:\n",
    "        final_strip = tf.concat(activations_list[H*W:N],axis=1)\n",
    "        final_strip = tf.pad(final_strip,tf.constant([[0,0],[0,(H-diff)*padded_activations.shape.as_list()[1]],[0,0],[0,0]]),'CONSTANT')\n",
    "        activation_strips.append(final_strip)\n",
    "    activation_image = tf.concat(activation_strips,axis=2)            \n",
    "    if scale_up:\n",
    "        activation_image = tf.divide(activation_image, tf.reduce_max(activation_image))\n",
    "\n",
    "    return activation_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(train_init_op)\n",
    "activations = tf.layers.conv2d(images,64,(3,3),(1,1),padding='SAME')\n",
    "sess.run(tf.global_variables_initializer())\n",
    "I, M, KM, P, L = sess.run([images, masks, kpt_masks, pts, labels])\n",
    "WI = getFilterImage(tf.expand_dims(tf.trainable_variables()[0],0))\n",
    "AI = getActivationImage(activations)\n",
    "plt.figure(figsize=[8,4])\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(WI.eval()[0])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(AI.eval()[0,:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Keypoint Visualizations Overlaid on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(train_init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scale = 2.0\n",
    "def keypointHeatMapOverlay(images, kpt_masks, d=d, scale=2.0, threshold=0.1, grayscale=True):  \n",
    "    images_scaled = tf.image.resize_bilinear(images, kpt_masks.shape[1:3]) # resize\n",
    "    image_tile = getFilterImage(tf.stack([images_scaled for i in range(17)],axis=4)) # tile\n",
    "    if grayscale == True:\n",
    "        image_tile = tf.reduce_mean(image_tile,axis=3,keep_dims=True) # grayscale\n",
    "    image_tile = tf.divide(image_tile, tf.reduce_max(image_tile)) # normalize\n",
    "\n",
    "    # normalize individual keypoint masks\n",
    "    keypoint_masks = tf.divide(kpt_masks, tf.reduce_max(kpt_masks,axis=[1,2], keep_dims=True))\n",
    "    keypoint_tile = getActivationImage(keypoint_masks) # tile\n",
    "#     keypoint_tile = tf.divide(keypoint_tile, tf.reduce_max(keypoint_tile)) # normalize\n",
    "    \n",
    "    image_tile = image_tile*tf.to_float(tf.less_equal(keypoint_tile,threshold)) # zero at keypoint locations?\n",
    "    keypoint_tile = tf.concat([keypoint_tile, tf.zeros_like(keypoint_tile),tf.zeros_like(keypoint_tile)],axis=3) # map to R color channel\n",
    "\n",
    "    flattened_tile = image_tile + scale * keypoint_tile\n",
    "    \n",
    "    return flattened_tile\n",
    "\n",
    "flattened_tile = keypointHeatMapOverlay(images, kpt_masks)\n",
    "\n",
    "I, KM, FL = sess.run([images, kpt_masks, flattened_tile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=[16,10])\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(I[i,:,:,:]/255.0)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(FL[i]/scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kpts = tf.reshape(pts,[-1,2,17])\n",
    "indices = tf.to_int32(kpts)\n",
    "\n",
    "kp_mask1 = tf.one_hot(depth=d,indices=indices[:,1,:],axis=0)\n",
    "kp_mask2 = tf.one_hot(depth=d,indices=indices[:,0,:],axis=1)\n",
    "\n",
    "kp_masks = tf.matmul(tf.transpose(kp_mask1,(2,0,1)),tf.transpose(kp_mask2,(2,0,1)))\n",
    "kp_masks = tf.transpose(kp_masks,(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.stack([tf.linspace(0.0,d,d) for i in range(kpts.shape[-1])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pts.eval().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero labels for all images with padding (in case that's the problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cropped_image = tf.placeholder(tf.float32, [1,224,180,3])\n",
    "padded_image = tf.placeholder(tf.float32, [1,224,224,3])\n",
    "\n",
    "labels = tf.ones([1,17])\n",
    "square = tf.reduce_min(tf.to_float(tf.equal(cropped_image.shape, padded_image.shape)))\n",
    "\n",
    "labels = square * labels\n",
    "labels.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hourglass rework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def HourGlassNet(graph, inputs=None, num_levels=5, base_filters = 64, scalar_summary_list=None, image_summary_list=None, histogram_summary_list=None):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    - net \n",
    "    - summary lists\n",
    "    \"\"\"\n",
    "    ###################################################\n",
    "    ################### HOURGLASS 1 ###################\n",
    "    ###################################################\n",
    "    with graph.as_default():\n",
    "        # Initialize summaries\n",
    "        if scalar_summary_list is None:\n",
    "            scalar_summary_list = []\n",
    "        if image_summary_list is None:\n",
    "            image_summary_list = []\n",
    "        if histogram_summary_list is None:\n",
    "            histogram_summary_list = []\n",
    "            \n",
    "        bridges = {}\n",
    "        bases = {}\n",
    "        with tf.variable_scope('Hourglass'):\n",
    "            with tf.variable_scope('base'):\n",
    "                base = inputs\n",
    "\n",
    "            for level in range(num_levels):\n",
    "                # Bridge - maintain constant size\n",
    "                bridge_filters = base_filters * 2 ** level\n",
    "                with tf.variable_scope('level_{}_bridge'.format(level+1)):\n",
    "                    bridge = base\n",
    "                    for i in range(num_levels - level):\n",
    "                        bridge = tf.layers.dropout(bridge,rate=0.5)\n",
    "                        bridge = tf.layers.conv2d(bridge,bridge_filters,(3,3),strides=(1,1),padding='SAME')\n",
    "                        bridge = tf.layers.batch_normalization(bridge,axis=3)\n",
    "                        bridge = tf.nn.relu(bridge)\n",
    "                    bridges[level] = bridge\n",
    "\n",
    "                if level < num_levels - 1:\n",
    "                    with tf.variable_scope('level_{}'.format(level+1)):\n",
    "                        # Base - decrease size by factor of 2 for n\n",
    "                        base = tf.layers.dropout(base,rate=0.5)\n",
    "                        base = tf.layers.conv2d(base,bridge_filters,(3,3),strides=(2,2),padding='SAME')\n",
    "                        base = tf.layers.batch_normalization(base,axis=3)\n",
    "                        base = tf.nn.relu(base)\n",
    "                    \n",
    "            for i in range(num_levels):\n",
    "                print(i, bridges[i].shape)\n",
    "                    \n",
    "            for level in reversed(range(0,num_levels)):\n",
    "                # resize_bilinear or upconv?\n",
    "                # output = tf.image.resize_bilinear(ouput,size=2*output.shape[1:2])\n",
    "                with tf.variable_scope('level_{}_up'.format(level)):\n",
    "                    out_filters = int(base_filters * 2 ** (level-1))\n",
    "                    output = bridges[level]\n",
    "                    output = tf.layers.dropout(output,rate=0.5)\n",
    "                    output = tf.layers.conv2d_transpose(output,out_filters,(3,3),(2,2),padding='SAME')\n",
    "                    output = tf.layers.batch_normalization(output,axis=3) # HERE OR AFTER CONCAT???\n",
    "                    output = tf.nn.relu(output) # HERE OR AFTER CONCAT???\n",
    "\n",
    "                    if level > 0:\n",
    "                        bridges[level-1] = tf.concat([bridges[level-1],output],axis=3)\n",
    "                    \n",
    "            for i in reversed(range(num_levels)):\n",
    "                print(i, bridges[i].shape)\n",
    "                \n",
    "            return head[0], scalar_summary_list, image_summary_list, histogram_summary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    images=tf.placeholder(tf.float32,[10,224,224,3])\n",
    "\n",
    "    print('Block1')\n",
    "    with tf.variable_scope('Block1'):\n",
    "        net,_,_,_ = HourGlassNet(graph, inputs=images, num_levels=5, base_filters = 64, scalar_summary_list=None, image_summary_list=None, histogram_summary_list=None)\n",
    "    \n",
    "    print('Block1')\n",
    "    with tf.variable_scope('Block2'):\n",
    "        net,_,_,_ = HourGlassNet(graph, inputs=images, num_levels=5, base_filters = 17, scalar_summary_list=None, image_summary_list=None, histogram_summary_list=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    images=tf.placeholder(tf.float32,[10,224,224,3])\n",
    "    num_levels=5\n",
    "    base_filters=64\n",
    "    inputs = tf.layers.conv2d(images,64,(3,3),(2,2),'SAME')\n",
    "    head = {}\n",
    "    \n",
    "    with tf.variable_scope('Hourglass'):\n",
    "        with tf.variable_scope('base'):\n",
    "            base = tf.layers.conv2d(inputs, base_filters, (3,3),strides=(1,1),padding='SAME')\n",
    "            base = tf.layers.batch_normalization(base,axis=3)\n",
    "            base = tf.nn.relu(base)\n",
    "\n",
    "        for level in range(num_levels):\n",
    "            # Bridge - maintain constant size\n",
    "            bridge_filters = base_filters * 2 ** level\n",
    "            with tf.variable_scope('level_{}_bridge'.format(level)):\n",
    "                bridge = base\n",
    "                for i in range(num_levels - level):\n",
    "                    bridge = tf.layers.dropout(bridge,rate=0.5)\n",
    "                    bridge = tf.layers.conv2d(bridge,bridge_filters,(3,3),strides=(1,1),padding='SAME')\n",
    "                    bridge = tf.layers.batch_normalization(bridge,axis=3)\n",
    "                    bridge = tf.nn.relu(bridge)\n",
    "                head[level] = bridge\n",
    "\n",
    "            with tf.variable_scope('level_{}'.format(level+1)):\n",
    "                # Base - decrease size by factor of 2 for n\n",
    "                base = tf.layers.dropout(base,rate=0.5)\n",
    "                base = tf.layers.conv2d(base,bridge_filters,(3,3),strides=(2,2),padding='SAME')\n",
    "                base = tf.layers.batch_normalization(base,axis=3)\n",
    "                base = tf.nn.relu(base)\n",
    "\n",
    "        for i in range(num_levels):\n",
    "            print(i, head[i].shape)\n",
    "            \n",
    "        for level in reversed(range(1,num_levels)):\n",
    "            # resize_bilinear or upconv?\n",
    "            # output = tf.image.resize_bilinear(ouput,size=2*output.shape[1:2])\n",
    "            with tf.variable_scope('level_{}_up'.format(level)):\n",
    "                out_filters = int(base_filters * 2 ** (level-1))\n",
    "                output = head[level]\n",
    "                output = tf.layers.dropout(output,rate=0.5)\n",
    "                output = tf.layers.conv2d_transpose(output,out_filters,(3,3),(2,2),padding='SAME')\n",
    "                output = tf.layers.batch_normalization(output,axis=3) # HERE OR AFTER CONCAT???\n",
    "                output = tf.nn.relu(output) # HERE OR AFTER CONCAT???\n",
    "\n",
    "                # if level > 0:\n",
    "                head[level-1] = tf.concat([head[level-1],output],axis=3)\n",
    "\n",
    "        for i in reversed(range(num_levels)):\n",
    "            print(i, head[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k,v in head.items():\n",
    "    print(k,v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
