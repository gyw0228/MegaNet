{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pylab\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "from tensorflow.contrib.layers.python.layers import utils\n",
    "\n",
    "import resnet_v2 as resnet\n",
    "# import cv2\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keypoint_CrossEntropyLoss(prediction_maps, keypoint_masks, labels, L=5.0, scope=\"keypointLoss\"):\n",
    "    \"\"\"\n",
    "    heat_maps = predictions from network\n",
    "    keypoints (N,17,2) = actual keypoint locations\n",
    "    labels (N,17,1) = 0 if invalid, 1 if occluded, 2 if valid\n",
    "    \"\"\"\n",
    "    losses = tf.nn.sigmoid_cross_entropy_with_logits(logits=prediction_maps,labels=keypoint_masks)\n",
    "    labels = tf.reshape(labels,[-1,1,1,17])\n",
    "    losses = tf.multiply(losses,labels) # set loss to zero for invalid keypoints (labels=0)\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keypoint_SquaredErrorLoss(prediction_maps, keypoint_masks, labels, L=5.0, scope=\"keypointLoss\"):\n",
    "    \"\"\"\n",
    "    heat_maps = predictions from network\n",
    "    keypoints (N,17,2) = actual keypoint locations\n",
    "    labels (N,17,1) = 0 if invalid, 1 if occluded, 2 if valid\n",
    "    \"\"\"\n",
    "    losses = tf.squared_difference(prediction_maps,keypoint_masks)\n",
    "    labels = tf.reshape(labels,[-1,1,1,17])\n",
    "    losses = tf.multiply(losses,labels) # set loss to zero for invalid keypoints (labels=0)\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=9.81s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "def get_data(base_dir,image_dir,ann_file):\n",
    "    image_path = '{}/images/{}'.format(baseDir,image_dir)\n",
    "    ann_path='{}/annotations/{}.json'.format(baseDir,ann_file)\n",
    "\n",
    "    return image_path, ann_path\n",
    "    \n",
    "# define the path to the annotation file corresponding to the images you want to work with\n",
    "baseDir='/Users/kyle/Repositories/coco'\n",
    "\n",
    "trainData='person_keypoints_train2014'\n",
    "valData='person_keypoints_val2014'\n",
    "testData='image_info_test-dev2015'\n",
    "\n",
    "imageTrainDir = 'train2014'\n",
    "imageValDir = 'val2014'\n",
    "imageTestDir = 'test2015'\n",
    "\n",
    "train_img_path, train_ann_path = get_data(baseDir,imageTrainDir,trainData)\n",
    "val_img_path, val_ann_path = get_data(baseDir,imageValDir,valData)\n",
    "\n",
    "# initialize a coco object\n",
    "coco = COCO(train_ann_path)\n",
    "\n",
    "# get all images containing the 'person' category\n",
    "catIds = coco.getCatIds(catNms=['person'])\n",
    "imgIds = coco.getImgIds(catIds=catIds)\n",
    "\n",
    "# Just for dealing with the images on my computer (not necessary when working with the whole dataset)\n",
    "catIds = imgIds[0:30]\n",
    "imgIds = imgIds[0:30]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    VGG_MEAN = tf.reshape(tf.constant([123.68, 116.78, 103.94]),[1,1,3])\n",
    "    NUM_KEYPOINTS = 17\n",
    "    BATCH_SIZE = 10\n",
    "    L = 10.0 # keypoint effective radius\n",
    "    \n",
    "    def extract_annotations(filename, imgID, coco=coco):\n",
    "        anns = coco.loadAnns(coco.getAnnIds(imgID,catIds=[1],iscrowd=None))\n",
    "        ann = max([ann for ann in anns], key=lambda item:item['area']) # extract annotation for biggest instance\n",
    "        bbox = np.array(np.floor(ann['bbox']),dtype=int)\n",
    "        keypoints = np.reshape(ann['keypoints'],(-1,3))\n",
    "        mask = coco.annToMask(ann)\n",
    "        \n",
    "        return filename, bbox, keypoints, mask\n",
    "    \n",
    "    def preprocess_image_tf(filename, bbox_tensor, keypoints_tensor, mask, D = tf.constant(256.0)):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        resized_image (N,D,D,3) - cropped, padded (if needed), scaled to square image of size D\n",
    "        resized_mask (N,D,D,1) - cropped, padded (if needed), scaled to square mask of size D\n",
    "        pts (N,2,17) - keypoint coordinates (i,j) scaled to match up with resized_image\n",
    "        labels (N,1,17) - values corresponding to pts: {0: invalid, 1:occluded, 2:valid}\n",
    "        \"\"\"\n",
    "        image_string = tf.read_file(filename)\n",
    "        image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "        image = tf.cast(image_decoded, tf.float32)\n",
    "\n",
    "        mask = tf.transpose([mask],[1,2,0])\n",
    "        bbox_tensor = tf.to_float(bbox_tensor)\n",
    "        keypoints_tensor = tf.to_float(keypoints_tensor)\n",
    "\n",
    "        sideLength = tf.reduce_max(bbox_tensor[2:],axis=0)\n",
    "        centerY = tf.floor(bbox_tensor[0] + tf.divide(bbox_tensor[2],tf.constant(2.0)))\n",
    "        centerX = tf.floor(bbox_tensor[1] + tf.divide(bbox_tensor[3],tf.constant(2.0)))\n",
    "        center = tf.stack([centerY,centerX])\n",
    "\n",
    "        corner1 = tf.to_int32(tf.minimum(tf.maximum(tf.subtract(center, tf.divide(sideLength,tf.constant(2.0))),0),\n",
    "                             tf.reverse(tf.to_float(tf.shape(image)[:2]),tf.constant([0]))))\n",
    "        corner2 = tf.to_int32(tf.minimum(tf.maximum(tf.add(center, tf.divide(sideLength,tf.constant(2.0))),0),\n",
    "                             tf.reverse(tf.to_float(tf.shape(image)[:2]),tf.constant([0]))))\n",
    "        i_shape = tf.subtract(corner2,corner1)\n",
    "        d_shape = tf.subtract(tf.to_int32(sideLength),i_shape)\n",
    "\n",
    "        scale = tf.divide(D, sideLength)\n",
    "        cropped_image = tf.image.crop_to_bounding_box(image,corner1[1],corner1[0],\n",
    "                                                      tf.subtract(corner2,corner1)[1],tf.subtract(corner2,corner1)[0])\n",
    "        cropped_mask = tf.image.crop_to_bounding_box(mask,corner1[1],corner1[0],\n",
    "                                                      tf.subtract(corner2,corner1)[1],tf.subtract(corner2,corner1)[0])\n",
    "\n",
    "        dX = tf.floor(tf.divide(d_shape,tf.constant(2)))\n",
    "        dY = tf.ceil(tf.divide(d_shape,tf.constant(2)))\n",
    "\n",
    "        pts, labels = tf.split(keypoints_tensor,[2,1],axis=1)\n",
    "        pts = tf.subtract(pts,tf.to_float(corner1)) # shift keypoints\n",
    "        pts = tf.add(pts,tf.to_float(dX)) # shift keypoints\n",
    "        pts = tf.multiply(pts,scale) # scale keypoints\n",
    "\n",
    "        # set invalid pts to 0\n",
    "        inbounds = tf.less(pts,D)\n",
    "        inbounds = tf.multiply(tf.to_int32(inbounds), tf.to_int32(tf.greater(pts,0)))\n",
    "        pts = tf.multiply(pts,tf.to_float(inbounds))\n",
    "        pts = tf.transpose(pts,[1,0])\n",
    "        labels = tf.transpose(labels,[1,0])\n",
    "\n",
    "        padded_image = tf.image.pad_to_bounding_box(cropped_image,tf.to_int32(dX[1]),tf.to_int32(dX[0]),\n",
    "                                                    tf.to_int32(sideLength),tf.to_int32(sideLength))\n",
    "        padded_mask = tf.image.pad_to_bounding_box(cropped_mask,tf.to_int32(dX[1]),tf.to_int32(dX[0]),\n",
    "                                                    tf.to_int32(sideLength),tf.to_int32(sideLength))\n",
    "\n",
    "        resized_image = tf.image.resize_images(padded_image,tf.constant([256,256]),tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        resized_image = resized_image - VGG_MEAN\n",
    "        resized_mask = tf.image.resize_images(padded_mask,tf.constant([256,256]),tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        return resized_image, resized_mask, pts, labels\n",
    "\n",
    "    def scaleDownMaskAndKeypoints(image, mask, pts, labels):\n",
    "        mask = tf.image.resize_images(mask,tf.constant([128,128]),tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        pts = tf.multiply(pts,tf.constant(0.5))\n",
    "        return image, mask, pts, labels\n",
    "    \n",
    "    def generate_keypoint_masks(image, mask, keypoints, labels, D=128.0, L=L):\n",
    "        X, Y = tf.meshgrid(tf.linspace(0.0,128.0,128),tf.linspace(0.0,128.0,128))\n",
    "        X = tf.reshape(X,[128,128,1])\n",
    "        Y = tf.reshape(Y,[128,128,1])\n",
    "        X_stack = tf.tile(X,tf.constant([1,1,17],dtype=tf.int32))\n",
    "        Y_stack = tf.tile(Y,tf.constant([1,1,17],dtype=tf.int32))\n",
    "\n",
    "        pts = tf.reshape(keypoints,[1,2,17])\n",
    "        ptsX, ptsY = tf.split(pts,[1,1],axis=1)\n",
    "        d1 = tf.square(tf.subtract(X_stack,ptsX))\n",
    "        d2 = tf.square(tf.subtract(Y_stack,ptsY))\n",
    "\n",
    "        pt_masks = tf.multiply(tf.divide(tf.constant(1.0),tf.add(d1,d2)+L),L)\n",
    "        return image, mask, pt_masks, pts, labels\n",
    "    \n",
    "    ########## DATASET ###########\n",
    "    \n",
    "    with tf.variable_scope(\"DataSet\"):\n",
    "        # Initialize train_dataset\n",
    "        filenames = tf.constant(['{}/COCO_train2014_{:0>12}.jpg'.format(train_img_path,imgID) for imgID in imgIds])\n",
    "        imgID_tensor = tf.constant(imgIds)\n",
    "\n",
    "        train_dataset = tf.contrib.data.Dataset.from_tensor_slices((filenames,imgID_tensor))\n",
    "        # Extract Annotations via coco interface\n",
    "        train_dataset = train_dataset.map(lambda filename, imgID: tf.py_func(extract_annotations, [filename, imgID], \n",
    "                                                                     [filename.dtype, tf.int64, tf.int64, tf.uint8]))\n",
    "        # All other preprocessing in tensorflow\n",
    "        train_dataset = train_dataset.map(preprocess_image_tf)\n",
    "        train_dataset = train_dataset.map(scaleDownMaskAndKeypoints)\n",
    "        train_dataset = train_dataset.map(generate_keypoint_masks)\n",
    "\n",
    "        # BATCH\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "        train_dataset = train_dataset.batch(10) # must resize images to make them match\n",
    "        iterator = tf.contrib.data.Iterator.from_structure(train_dataset.output_types,train_dataset.output_shapes)\n",
    "        # resized_image, resized_mask, pts, labels = iterator.get_next()\n",
    "#         images, masks, pts, labels = iterator.get_next()\n",
    "        images, masks, kpt_masks, pts, labels = iterator.get_next()\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "        \n",
    "    \n",
    "    ##################################################################\n",
    "    ##################### BACKBONE ARCHITECTURE ######################\n",
    "    ##################################################################\n",
    "    \n",
    "    resnet_v2 = tf.contrib.slim.nets.resnet_v2\n",
    "    with slim.arg_scope(resnet_v2.resnet_arg_scope()):\n",
    "        logits, endpoints = resnet_v2.resnet_v2_50(\n",
    "            inputs=images,\n",
    "            num_classes=10,\n",
    "            is_training=is_training,\n",
    "            reuse=None,\n",
    "            output_stride=16,\n",
    "            scope='resnet_v2_50'\n",
    "            )\n",
    "\n",
    "        model_path = 'checkpoints/resnet_v2_50.ckpt'\n",
    "        assert(os.path.isfile(model_path))\n",
    "        # Backbone Variables - remember to exclude all variables above backbone (including block4 and logits)\n",
    "        variables_to_restore = tf.contrib.framework.get_variables_to_restore(exclude=['resnet_v2_50/postnorm','resnet_v2_50/logits'])\n",
    "        # Head variables\n",
    "        # Note: We would need another set of variables and another initializer to capture the logits as well\n",
    "        other_variables = tf.contrib.framework.get_variables('resnet_v2_50/postnorm')\n",
    "\n",
    "    \n",
    "    ##################################################################\n",
    "    ####################### HEAD ARCHITECTURE ########################\n",
    "    ##################################################################\n",
    "    \n",
    "    HEAD_SCOPE = 'NetworkHead'\n",
    "    PREDICTION_THRESHOLD = 0.5\n",
    "\n",
    "    with tf.variable_scope(HEAD_SCOPE):\n",
    "        block1 = endpoints['resnet_v2_50/block1']\n",
    "        block2 = endpoints['resnet_v2_50/block2']\n",
    "        block3 = endpoints['resnet_v2_50/block3']\n",
    "        block4 = endpoints['resnet_v2_50/block4']\n",
    "\n",
    "        with tf.variable_scope('Layer1'):\n",
    "            b1 = tf.layers.conv2d(block1, 64, kernel_size=(3,3), strides=(1,1),padding='SAME',activation=tf.nn.relu)\n",
    "            b2 = tf.layers.conv2d(block2, 128, kernel_size=(3,3), strides=(1,1),padding='SAME',activation=tf.nn.relu)\n",
    "            b3 = tf.layers.conv2d(block3, 128, kernel_size=(1,1), strides=(1,1),padding='SAME',activation=tf.nn.relu)\n",
    "            b4 = tf.layers.conv2d(block4, 128, kernel_size=(1,1), strides=(1,1),padding='SAME',activation=tf.nn.relu)\n",
    "\n",
    "        with tf.variable_scope('Layer2'):\n",
    "            b1 = tf.layers.conv2d(block1, 32, kernel_size=(3,3), strides=(1,1),padding='SAME',activation=tf.nn.relu)\n",
    "\n",
    "            b2 = tf.layers.conv2d_transpose(b2, 32, kernel_size=(3,3), strides=(2,2),padding='VALID',activation=tf.nn.relu)\n",
    "            b3 = tf.layers.conv2d_transpose(b3, 64, kernel_size=(3,3), strides=(2,2),padding='VALID',activation=tf.nn.relu)\n",
    "            b4 = tf.layers.conv2d_transpose(b4, 64, kernel_size=(3,3), strides=(2,2),padding='VALID',activation=tf.nn.relu)\n",
    "\n",
    "            b2 = tf.slice(b2,[0,1,1,0],b2.shape - np.array([0, 2, 2, 0]))\n",
    "            b3 = tf.slice(b3,[0,1,1,0],b3.shape - np.array([0, 2, 2, 0]))\n",
    "            b4 = tf.slice(b4,[0,1,1,0],b4.shape - np.array([0, 2, 2, 0]))\n",
    "\n",
    "        with tf.variable_scope('BatchNorm'):\n",
    "            b1 = tf.layers.batch_normalization(b1)\n",
    "            b2 = tf.layers.batch_normalization(b2)\n",
    "            b3 = tf.layers.batch_normalization(b3)\n",
    "            b4 = tf.layers.batch_normalization(b4)\n",
    "\n",
    "        with tf.variable_scope('Funnel'):\n",
    "            head = tf.concat([b1,b2,b3,b4],axis=3)\n",
    "\n",
    "        with tf.variable_scope('MaskHead'):\n",
    "            mask_head = tf.layers.conv2d_transpose(head, 16, (3,3), (2,2), padding='VALID', activation=tf.nn.relu)\n",
    "            mask_head = tf.slice(mask_head,[0,1,1,0],mask_head.shape - np.array([0, 2, 2, 0]))\n",
    "            mask_head = tf.layers.conv2d(mask_head, 1, (1,1), (1,1), padding='SAME', activation=None)\n",
    "\n",
    "        with tf.variable_scope('KeypointHead'):\n",
    "            keypoint_head = tf.layers.conv2d_transpose(head, 32, (3,3), (2,2), padding='VALID', activation = tf.nn.relu)\n",
    "            keypoint_head = tf.slice(keypoint_head,[0,1,1,0],keypoint_head.shape - np.array([0, 2, 2, 0]))\n",
    "            keypoint_head = tf.layers.conv2d(keypoint_head, 17, (1,1), (1,1), padding='SAME', activation=None)\n",
    "\n",
    "        with tf.variable_scope('MaskPrediction'):\n",
    "            mask_prediction = tf.nn.sigmoid(mask_head)\n",
    "            mask_prediction = tf.to_float(tf.greater_equal(mask_prediction, PREDICTION_THRESHOLD))\n",
    "\n",
    "        with tf.variable_scope('KeypointsPrediction'):\n",
    "            keypoint_prediction = tf.nn.sigmoid(keypoint_head)\n",
    "            keypoint_prediction = tf.to_float(tf.greater_equal(keypoint_prediction, PREDICTION_THRESHOLD))\n",
    "\n",
    "            \n",
    "            \n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        file_writer = tf.summary.FileWriter('/tmp/HourGlassNet/1')\n",
    "        file_writer.add_graph(sess.graph)\n",
    "        \n",
    "        # initialize variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # initialize dataset\n",
    "        sess.run(train_init_op) \n",
    "        masks, kpt_masks, mask_pred, kpt_pred, mask_loss, kpt_loss = sess.run([masks, kpt_masks, maskPrediction, \n",
    "                                                             keypointPredictions, maskLoss, keypointLoss])\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 3\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(mask_pred[i][:,:,0])\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(kpt_pred[i][:,:,0])\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(masks[i][:,:,0])\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(np.sum(kpt_masks[i],axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init_fn(sess)  # load the pretrained weights\n",
    "# sess.run(fc8_init)  # initialize the new fc8 layer\n",
    "sess.run(train_init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# resized_image, resized_mask, pts, labels = sess.run(next_element)\n",
    "\n",
    "try:\n",
    "    I, M, P, L = sess.run([images, masks, pts, labels], {is_training: True})\n",
    "    plt.imshow(I[0])\n",
    "    plt.imshow(M[0][:,:,0],alpha=0.5)\n",
    "    plt.scatter(P[0][(np.reshape(L[0],-1)==2),0],P[0][(np.reshape(L[0],-1)==2),1],c=\"r\")\n",
    "except tf.errors.OutOfRangeError:\n",
    "    sess.run(train_init_op)\n",
    "    print(\"Reinitialized Dataset Iterator...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Playing around with ResNet V2 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "D = 225\n",
    "images = tf.placeholder(tf.float32, (BATCH_SIZE,D,D,3))\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "resnet_v2 = tf.contrib.slim.nets.resnet_v2\n",
    "with slim.arg_scope(resnet_v2.resnet_arg_scope()):\n",
    "    logits, endpoints = resnet_v2.resnet_v2_50(\n",
    "        inputs=images,\n",
    "        num_classes=10,\n",
    "        is_training=is_training,\n",
    "        reuse=None,\n",
    "        output_stride=16,\n",
    "        scope='resnet_v2_50'\n",
    "        )\n",
    "\n",
    "# model_path = 'checkpoints/resnet_v2_50.ckpt'\n",
    "# assert(os.path.isfile(model_path))\n",
    "# # Backbone Variables - remember to exclude all variables above backbone (including block4 and logits)\n",
    "# variables_to_restore = tf.contrib.framework.get_variables_to_restore(exclude=['resnet_v2_50/block4','resnet_v2_50/postnorm','resnet_v2_50/logits'])\n",
    "# # Head variables\n",
    "# # Note: We would need another set of variables and another initializer to capture the logits as well\n",
    "# other_variables = tf.contrib.framework.get_variables('resnet_v2_50/block4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def highestPrimeFactorization(n):    \n",
    "    return [(i, n//i) for i in range(1, int(n**0.5) + 1) if n % i == 0][-1]\n",
    "\n",
    "def getFilterImageSummary(filters,name=None):\n",
    "    padded_filters = tf.pad(filters,tf.constant([[0,0],[1,1],[1,1],[0,0],[0,0]]),'CONSTANT')\n",
    "    filter_list = tf.unstack(padded_filters,axis=4)    \n",
    "    H,W = highestPrimeFactorization(len(filter_list))\n",
    "    weight_strips = [tf.concat(filter_list[8*i:8*(i+1)],axis=1) for i in range(W)]\n",
    "    weight_image = tf.concat(weight_strips,axis=2)\n",
    "    return weight_image\n",
    "    \n",
    "def getActivationImageSummary(activations,name=None):\n",
    "    padded_activations = tf.pad(activations,tf.constant([[0,0],[1,0],[1,0],[0,0]]),'CONSTANT')\n",
    "    expanded_activations = tf.expand_dims(padded_activations,axis=3)\n",
    "    activations_list = tf.unstack(expanded_activations,axis=4)\n",
    "    H,W = highestPrimeFactorization(len(activations_list))\n",
    "    activation_strips = [tf.concat(activations_list[H*i:H*(i+1)],axis=1) for i in range(W)]\n",
    "    activation_image = tf.concat(activation_strips,axis=2)\n",
    "    return activation_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([10, 57, 57, 1], [10, 57, 57, 17])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HEAD_SCOPE = 'NetworkHead'\n",
    "PREDICTION_THRESHOLD = 0.5\n",
    "\n",
    "with tf.variable_scope(HEAD_SCOPE):\n",
    "    block1 = endpoints['resnet_v2_50/block1']\n",
    "    block2 = endpoints['resnet_v2_50/block2']\n",
    "    block3 = endpoints['resnet_v2_50/block3']\n",
    "    block4 = endpoints['resnet_v2_50/block4']\n",
    "    \n",
    "    with tf.variable_scope('Layer1'):\n",
    "        b1 = tf.layers.conv2d(block1, 64, kernel_size=(3,3), strides=(1,1),padding='SAME',activation=tf.nn.relu)\n",
    "        b2 = tf.layers.conv2d(block2, 128, kernel_size=(3,3), strides=(1,1),padding='SAME',activation=tf.nn.relu)\n",
    "        b3 = tf.layers.conv2d(block3, 128, kernel_size=(1,1), strides=(1,1),padding='SAME',activation=tf.nn.relu)\n",
    "        b4 = tf.layers.conv2d(block4, 128, kernel_size=(1,1), strides=(1,1),padding='SAME',activation=tf.nn.relu)\n",
    "    \n",
    "    with tf.variable_scope('Layer2'):\n",
    "        b1 = tf.layers.conv2d(block1, 32, kernel_size=(3,3), strides=(1,1),padding='SAME',activation=tf.nn.relu)\n",
    "\n",
    "        b2 = tf.layers.conv2d_transpose(b2, 32, kernel_size=(3,3), strides=(2,2),padding='VALID',activation=tf.nn.relu)\n",
    "        b3 = tf.layers.conv2d_transpose(b3, 64, kernel_size=(3,3), strides=(2,2),padding='VALID',activation=tf.nn.relu)\n",
    "        b4 = tf.layers.conv2d_transpose(b4, 64, kernel_size=(3,3), strides=(2,2),padding='VALID',activation=tf.nn.relu)\n",
    "\n",
    "        b2 = tf.slice(b2,[0,1,1,0],b2.shape - np.array([0, 2, 2, 0]))\n",
    "        b3 = tf.slice(b3,[0,1,1,0],b3.shape - np.array([0, 2, 2, 0]))\n",
    "        b4 = tf.slice(b4,[0,1,1,0],b4.shape - np.array([0, 2, 2, 0]))\n",
    "    \n",
    "    with tf.variable_scope('BatchNorm'):\n",
    "        b1 = tf.layers.batch_normalization(b1)\n",
    "        b2 = tf.layers.batch_normalization(b2)\n",
    "        b3 = tf.layers.batch_normalization(b3)\n",
    "        b4 = tf.layers.batch_normalization(b4)\n",
    "        \n",
    "    with tf.variable_scope('Funnel'):\n",
    "        head = tf.concat([b1,b2,b3,b4],axis=3)\n",
    "\n",
    "    with tf.variable_scope('MaskHead'):\n",
    "        mask_head = tf.layers.conv2d_transpose(head, 16, (3,3), (2,2), padding='VALID', activation=tf.nn.relu)\n",
    "        mask_head = tf.slice(mask_head,[0,1,1,0],mask_head.shape - np.array([0, 2, 2, 0]))\n",
    "        mask_head = tf.layers.conv2d(mask_head, 1, (1,1), (1,1), padding='SAME', activation=None)\n",
    "        \n",
    "    with tf.variable_scope('KeypointHead'):\n",
    "        keypoint_head = tf.layers.conv2d_transpose(head, 32, (3,3), (2,2), padding='VALID', activation = tf.nn.relu)\n",
    "        keypoint_head = tf.slice(keypoint_head,[0,1,1,0],keypoint_head.shape - np.array([0, 2, 2, 0]))\n",
    "        keypoint_head = tf.layers.conv2d(keypoint_head, 17, (1,1), (1,1), padding='SAME', activation=None)\n",
    "        \n",
    "    with tf.variable_scope('MaskPrediction'):\n",
    "        mask_prediction = tf.nn.sigmoid(mask_head)\n",
    "        mask_prediction = tf.to_float(tf.greater_equal(mask_prediction, PREDICTION_THRESHOLD))\n",
    "        \n",
    "    with tf.variable_scope('KeypointsPrediction'):\n",
    "        keypoint_prediction = tf.nn.sigmoid(keypoint_head)\n",
    "        keypoint_prediction = tf.to_float(tf.greater_equal(keypoint_prediction, PREDICTION_THRESHOLD))\n",
    "\n",
    "    \n",
    "mask_prediction.get_shape().as_list(), keypoint_prediction.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VGG_MEAN = tf.reshape(tf.constant([0.0, 0.0, 0.0]),[1,1,3])\n",
    "NUM_KEYPOINTS = 17\n",
    "BATCH_SIZE = 10\n",
    "L = 10.0 # keypoint effective radius\n",
    "\n",
    "def extract_annotations(filename, imgID, coco=coco):\n",
    "    anns = coco.loadAnns(coco.getAnnIds(imgID,catIds=[1],iscrowd=None))\n",
    "    ann = max([ann for ann in anns], key=lambda item:item['area']) # extract annotation for biggest instance\n",
    "    bbox = np.array(np.floor(ann['bbox']),dtype=int)\n",
    "    keypoints = np.reshape(ann['keypoints'],(-1,3))\n",
    "    mask = coco.annToMask(ann)\n",
    "\n",
    "    return filename, bbox, keypoints, mask\n",
    "\n",
    "def preprocess_image_tf(filename, bbox_tensor, keypoints_tensor, mask, D = tf.constant(256.0)):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    resized_image (N,D,D,3) - cropped, padded (if needed), scaled to square image of size D\n",
    "    resized_mask (N,D,D,1) - cropped, padded (if needed), scaled to square mask of size D\n",
    "    pts (N,2,17) - keypoint coordinates (i,j) scaled to match up with resized_image\n",
    "    labels (N,1,17) - values corresponding to pts: {0: invalid, 1:occluded, 2:valid}\n",
    "    \"\"\"\n",
    "    image_string = tf.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.cast(image_decoded, tf.float32)\n",
    "\n",
    "    mask = tf.transpose([mask],[1,2,0])\n",
    "    bbox_tensor = tf.to_float(bbox_tensor)\n",
    "    keypoints_tensor = tf.to_float(keypoints_tensor)\n",
    "\n",
    "    sideLength = tf.reduce_max(bbox_tensor[2:],axis=0)\n",
    "    centerY = tf.floor(bbox_tensor[0] + tf.divide(bbox_tensor[2],tf.constant(2.0)))\n",
    "    centerX = tf.floor(bbox_tensor[1] + tf.divide(bbox_tensor[3],tf.constant(2.0)))\n",
    "    center = tf.stack([centerY,centerX])\n",
    "\n",
    "    corner1 = tf.to_int32(tf.minimum(tf.maximum(tf.subtract(center, tf.divide(sideLength,tf.constant(2.0))),0),\n",
    "                         tf.reverse(tf.to_float(tf.shape(image)[:2]),tf.constant([0]))))\n",
    "    corner2 = tf.to_int32(tf.minimum(tf.maximum(tf.add(center, tf.divide(sideLength,tf.constant(2.0))),0),\n",
    "                         tf.reverse(tf.to_float(tf.shape(image)[:2]),tf.constant([0]))))\n",
    "    i_shape = tf.subtract(corner2,corner1)\n",
    "    d_shape = tf.subtract(tf.to_int32(sideLength),i_shape)\n",
    "\n",
    "    scale = tf.divide(D, sideLength)\n",
    "    cropped_image = tf.image.crop_to_bounding_box(image,corner1[1],corner1[0],\n",
    "                                                  tf.subtract(corner2,corner1)[1],tf.subtract(corner2,corner1)[0])\n",
    "    cropped_mask = tf.image.crop_to_bounding_box(mask,corner1[1],corner1[0],\n",
    "                                                  tf.subtract(corner2,corner1)[1],tf.subtract(corner2,corner1)[0])\n",
    "\n",
    "    dX = tf.floor(tf.divide(d_shape,tf.constant(2)))\n",
    "    dY = tf.ceil(tf.divide(d_shape,tf.constant(2)))\n",
    "\n",
    "    pts, labels = tf.split(keypoints_tensor,[2,1],axis=1)\n",
    "    pts = tf.subtract(pts,tf.to_float(corner1)) # shift keypoints\n",
    "    pts = tf.add(pts,tf.to_float(dX)) # shift keypoints\n",
    "    pts = tf.multiply(pts,scale) # scale keypoints\n",
    "\n",
    "    # set invalid pts to 0\n",
    "    inbounds = tf.less(pts,D)\n",
    "    inbounds = tf.multiply(tf.to_int32(inbounds), tf.to_int32(tf.greater(pts,0)))\n",
    "    pts = tf.multiply(pts,tf.to_float(inbounds))\n",
    "    pts = tf.transpose(pts,[1,0])\n",
    "    labels = tf.transpose(labels,[1,0])\n",
    "\n",
    "    padded_image = tf.image.pad_to_bounding_box(cropped_image,tf.to_int32(dX[1]),tf.to_int32(dX[0]),\n",
    "                                                tf.to_int32(sideLength),tf.to_int32(sideLength))\n",
    "    padded_mask = tf.image.pad_to_bounding_box(cropped_mask,tf.to_int32(dX[1]),tf.to_int32(dX[0]),\n",
    "                                                tf.to_int32(sideLength),tf.to_int32(sideLength))\n",
    "\n",
    "    resized_image = tf.image.resize_images(padded_image,tf.constant([256,256]),tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    resized_image = resized_image - VGG_MEAN\n",
    "    resized_mask = tf.image.resize_images(padded_mask,tf.constant([256,256]),tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    return resized_image, resized_mask, pts, labels\n",
    "\n",
    "def scaleDownMaskAndKeypoints(image, mask, pts, labels):\n",
    "    mask = tf.image.resize_images(mask,tf.constant([128,128]),tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    pts = tf.multiply(pts,tf.constant(0.5))\n",
    "    return image, mask, pts, labels\n",
    "\n",
    "def generate_keypoint_masks(image, mask, pts, labels, D=128.0, L=L):\n",
    "    X, Y = tf.meshgrid(tf.linspace(0.0,128.0,128),tf.linspace(0.0,128.0,128))\n",
    "    X = tf.reshape(X,[128,128,1])\n",
    "    Y = tf.reshape(Y,[128,128,1])\n",
    "    X_stack = tf.tile(X,tf.constant([1,1,17],dtype=tf.int32))\n",
    "    Y_stack = tf.tile(Y,tf.constant([1,1,17],dtype=tf.int32))\n",
    "\n",
    "    pts = tf.reshape(pts,[1,2,17])\n",
    "    ptsX, ptsY = tf.split(pts,[1,1],axis=1)\n",
    "    d1 = tf.square(tf.subtract(X_stack,ptsX))\n",
    "    d2 = tf.square(tf.subtract(Y_stack,ptsY))\n",
    "\n",
    "    pt_masks = tf.multiply(tf.divide(tf.constant(1.0),tf.add(d1,d2)+L),L)\n",
    "    return image, mask, pt_masks, pts, labels\n",
    "\n",
    "########## DATASET ###########\n",
    "\n",
    "with tf.variable_scope(\"DataSet\"):\n",
    "    # Initialize train_dataset\n",
    "    filenames = tf.constant(['{}/COCO_train2014_{:0>12}.jpg'.format(train_img_path,imgID) for imgID in imgIds])\n",
    "    imgID_tensor = tf.constant(imgIds)\n",
    "\n",
    "    train_dataset = tf.contrib.data.Dataset.from_tensor_slices((filenames,imgID_tensor))\n",
    "    # Extract Annotations via coco interface\n",
    "    train_dataset = train_dataset.map(lambda filename, imgID: tf.py_func(extract_annotations, [filename, imgID], \n",
    "                                                                 [filename.dtype, tf.int64, tf.int64, tf.uint8]))\n",
    "    # All other preprocessing in tensorflow\n",
    "    train_dataset = train_dataset.map(preprocess_image_tf)\n",
    "    train_dataset = train_dataset.map(scaleDownMaskAndKeypoints)\n",
    "    train_dataset = train_dataset.map(generate_keypoint_masks)\n",
    "\n",
    "    # BATCH\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "    train_dataset = train_dataset.batch(10) # must resize images to make them match\n",
    "    iterator = tf.contrib.data.Iterator.from_structure(train_dataset.output_types,train_dataset.output_shapes)\n",
    "\n",
    "    images, masks, kpt_masks, pts, labels = iterator.get_next()\n",
    "    train_init_op = iterator.make_initializer(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(train_init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images.shape.as_list(), masks.shape.as_list(), kpt_masks.shape.as_list(), pts.shape.as_list(), labels.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KeypointPrediction(pred_masks, d):\n",
    "    \"\"\"\n",
    "    Input: Keypoint \"Heatmap\" Tensor\n",
    "    Output: Keypoint coordinates in tensor form\n",
    "    \"\"\"\n",
    "    x = tf.reshape(tf.linspace(0.5,d-0.5,d),[1,d,1,1])\n",
    "    pred = tf.multiply(kpt_masks, tf.to_float(tf.greater_equal(kpt_masks,0.5)))\n",
    "    pred_i = tf.reduce_sum(tf.multiply(pred, x),axis=[1,2])/tf.reduce_sum(pred,axis=[1,2])\n",
    "    pred_j = tf.reduce_sum(tf.multiply(pred, tf.transpose(x,(0,2,1,3))),axis=[1,2])/tf.reduce_sum(pred,axis=[1,2])\n",
    "    pred_pts = tf.stack([pred_j,pred_i],axis=1)\n",
    "    pred_pts = tf.expand_dims(pred_pts,axis=1)\n",
    "    return pred_pts\n",
    "\n",
    "def keypointPredictionAccuracy(pred_pts, true_pts, labels, threshold):\n",
    "    \"\"\"\n",
    "    Accuracy is a boolean: 1 if ||pred_pt-true_pt||^2 < threshold^2, 0 otherwise\n",
    "    \"\"\"\n",
    "    error = tf.multiply(tf.square(tf.subtract(pred_pts, true_pts)), tf.to_float(tf.greater_equal(labels, 1)))\n",
    "    accuracy = tf.reduce_mean(tf.to_float(tf.less(error,tf.square(threshold))))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ACC_THRESHOLD = 5.0\n",
    "pred_pts = KeypointPrediction(kpt_masks, 128)\n",
    "pred_mask = tf.random_uniform([10,128,128,1],0,2,tf.int32) # fake mask\n",
    "mask_accuracy = MaskAccuracy(pred_mask, masks)\n",
    "kp_accuracy = keypointPredictionAccuracy(pred_pts, pts, labels, ACC_THRESHOLD)\n",
    "I, M, KM, kPts, L, pPts, rP, kp_acc, m_acc = sess.run(\n",
    "    [images, masks, kpt_masks, pts, labels, pred_pts, ptsRev, kp_accuracy, mask_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[16,5])\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(np.sum(KM[0][:,:,:]*L[0],axis=2))\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(I[0])\n",
    "plt.subplot(1,3,3)\n",
    "plt.gca().set_facecolor('k')\n",
    "plt.scatter(kPts[0,0,0][L[0,0]!=0],-kPts[0,0,1][L[0,0]!=0],c='white',label=\"label\")\n",
    "plt.scatter(pPts[0,0,0][L[0,0]!=0],-pPts[0,0,1][L[0,0]!=0],c='red',s=15,label=\"prediction\")\n",
    "plt.axis(\"equal\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MaskAccuracy(pred_mask, true_mask):\n",
    "    overlap = tf.reduce_sum(tf.multiply(tf.to_float(pred_mask),tf.to_float(true_mask)),axis=[1,2,3])\n",
    "    score1 = tf.divide(overlap, tf.reduce_sum(tf.to_float(pred_mask),axis=[1,2,3]))\n",
    "    score2 = tf.divide(overlap, tf.reduce_sum(tf.to_float(true_mask),axis=[1,2,3]))\n",
    "    accuracy = tf.minimum(score1,score2)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0,100,200)\n",
    "mu = 23\n",
    "L = 10.0\n",
    "y = L / (L + (x - L)**2)\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_9:0' shape=(10, 57, 57, 17) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_dims = keypoint_head.shape.as_list()\n",
    "tf.reshape(tf.nn.softmax(\n",
    "        tf.reshape(keypoint_head, [-1,shape_dims[1]*shape_dims[2],17]), dim=1), \n",
    "           shape_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 57, 57, 17]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoint_head.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 57, 57, 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_head.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
